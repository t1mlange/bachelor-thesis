
    Background
    In this chapter, we introduce the necessary background. In s:dataflow, we explain the term static data flow analysis. We introduce concepts used to precisely solve data flow problems in s:ifds and s:ap. We reason the need for a simpler code representation in s:jimple and last, we introduce FlowDroid, the tool our work is based on, in s:flowdroid.

    Static Data Flow Analysis    In the field of compilers, there is a distinction between static and dynamic. Static generally refers to something that is decided at compile-time while dynamic refers to decisions taken at runtime. 
    
    Same distinction is also present for analyses. Dynamic analysis observes the run behavior of the program while static analysis works on a representation of the code. Both have different tradeoffs. Dynamic it is hard to achieve code coverage and static it is hard to only traverse the actually taken paths. Thus, in case of analysis, dynamic analysis is an underapproxmiation and static analysis is an overapproximation. In the following, we only consider static analysis.

    Khedker defines data flow analysis as follows:
    
        Data flow analysis is a process of deriving information about the run time behaviour of a program.
        Data flow analyses are used in many different ways. Compilers use it to apply optimizations, others use it for software verification and it is also used for reverse-engineering. A special kind of data flow analysis is taint analysis which falls under the category of reverse-engineering. In taint analysis, the goal is to find out whether the information contents of a certain statement flows through the program to another statement. Variables which contain such worthwhile information are tainted variables. This worthwhile information has to come from somewhere, the so-called sources. Sources can be any expression but are often methods and their returned values are considered tainted. On the other end, there are sinks which leak the worthwhile information. A data flow between a source and a sink is called leak. If you would apply taint analysis to the use case of tracking detection, a source would be a method returning a unique identifier and a sink would be a method which sents out data to the internet. When a leak is found, we know the receiving server is able to identify the device.

    Data flow analyses are categorized in sensitivities. Is this common knowledge? Didn't find a good source for this
    
        Flow Sensitivity: A flow-sensitive analysis can determine if a fact holds at a certain statement.
        Context Sensitivity: An interprocedural analysis is able to distinguish the context of a called method, e.g. knows the original call site at a return statement.
        Object Sensitivity: An analysis can distinguish field accesses on different objects.
        Field Sensitivity: An analysis can distinguish different field accesses on the same object.
        Path Sensitivity: An analysis takes conditional branches into account, e.g. uses the fact that the condition holds after the branch.
        Basically, data flow analyses are always flow-sensitive. A data flow fact is an logical assertion which is either true or false at a statement. Now, there are two different kinds of facts: may and must. For a must analysis, the fact must hold on all paths to this statement while a may analysis only guarantees that on one path the statement holds. The decision which kind fits has to be done on per data flow analysis. Taint analysis like FlowDroid are based on may analysis.
    
    
    
    
    
    
    


    
    
    
    
    
    
    
    
    

    IFDS    Original Definition
    Interprocedural finite distributive subset (IFDS) problems are a special class of a data flow analysis problem. All problems adhering to IFDS can be transformed into a graph-reachability problem and thus the solution is computable in polynomial time. It is context-sensitive and flow-sensitive by default.

    
    IFDS operates on a so-called exploded supergraph. Every node in the exploded supergraph is a tuple  of a statement  in the interprocedural control-flow graph and a dataflow fact . The domain is typically the set of variables in the program. Edges between two nodes  and  exist if  propagated over  yields  and  is a successor of . This already ensures flow-sensitivity.
    
    For context-sensitivity, IFDS only visits valid paths. Reps et al proposed a context-sensitive grammar which acts like a call stack to make sure there is no mismatch and the path is a valid execution path.

    
    To propagate facts over statements, we need to define rules on how the data flow changes when observing a statement. These rules are called flow functions. There are four types of flow functions:
    
        Call Flow: Edges from call statement into a method. The flow function maps the facts visible in the callee into it. 
        Return Flow: Edges returning from a method. The flow function maps the facts visible in the caller out of the callee.
        Call To Return Flow: Edges over a call statement. The flow function maps the facts not visible in the callee over the call statement.
        Normal Flow: Edges over every other statement. Often, this flow functions only handles assign statements.
        The incoming set of facts is all predecessors' outgoing facts merged together using a merge operator : 
    


    
    Now, we also want to introduce new facts. For that reason, the domain contains a zero fact and all nodes with  are always reachable, thus the zero fact holds at every steatment. Whenever we want to introduce a fact, we can model this in the flow function by deriving such facts from the zero fact . As an example, in taint analysis the flow functions map zero facts at sources to a tainted variable. 

    
    IFDS also utilizes summaries. After returning from a method, the algorithm solved a subproblem for which it remembers the results to be applied later. So, the proposed tabulation algorithm for solving the realizable path problem is a dynamic algorithm. 

    
    Eventually, there is no fact to propagate anymore and the analysis will terminate. This is either because the facts were killed by the flow functions or already have been seen at the nodes and thus, reached a fixpoint.

    For all this to work, the problems which can be formulated in IFDS have to abide to restrictions which are also eponymous:

    Distributive: The flow function must be distributive over the merge operator. Formally,  must hold at any time. Informally speaking, it does not matter whether facts get merged before or after applying the flow functions. By defining the flow function signature as  with a single fact as an input but a set of facts as output, this property is trivially satisfied. This property is required for the correctness because with distributiveness the maximum fixed point (MFP) equals meet over all valid paths (MOVP). 

    Finite: Another restriction is that the set of dataflow facts has to be finite. Let's go by a counterexample of what IFDS is not capable of: Answering "Which value is stored in variable x at statement s?".
    Now the dataflow fact is a tuple of the variable together with the stored value . Consider lst:ifdsfinite. Assume  is an integer of infinite precision for the domain to be infinite.
     is initialized to zero and passed into the method foo() multiple times. Now consider the summaries in lst:ifdsfinite_b. We never get to use one summary because the value always increases. Because of the same reason we also never reach a fixpoint. Thus, the domain has to be finite and in practice, also small as the domain is cubic in the time-complexity  .
    
    
                [b]0.45
                        max width=
                [gobble=20, morekeywords=RealInteger]
                    void main() 
                        RealInteger x = 0;
                        while (condition)
                            x = foo(x);
                    
                    
                    RealInteger foo(RealInteger x) 
                        return x + 42;
                    
                                        Code
                        [b]0.45
                        







            Summaries
                            Finitness example
            
    Subset: Data flow frameworks need to deal with merging the outcoming sets to a single incoming set. Essentially, to formalize the approximation and satisfy ordering constraints, data flow frameworks rely on lattices. IFDS also defines a underlying lattice on the powerset of the domain. The lattice ordering must be set inclusion. Following, the merge operator is set union or set intersect. Recall [s:dataflow]the last subsection with may and must. Here we can see the connection between the merge operator and may or must. The paper by Reps et al. later only establishes set union due to the duality of must and may not. This is also useful in practice as discussed in the [s:ifdspractical]next subsection.

  
    Practical Extensions    The original definition is inefficient in practice. Among others, Naeem et al proposed practical extensions to the IFDS framework to perform better in practice.

    Starting at the exploded supergraph, the original algorithm demands a fully built graph. Even in moderate programs the domain can get quite large and as the nodes in the exploded supergraph are the cross product of the domain and interprocedural call-graph nodes, it is infeasible to generate the full graph beforehand. Because there is no way to know before which part of the supergraph is actually needed, it is generated ad-hoc. This also removes the restriction on a small domain, now IFDS is also feasible if the encoutered subset of the domain is small enough.
    The restrictions on the domain set can be loosened even more. Bodden suggests in-practice the domain can be infinite and only the observed facts must adhere to the ascending-chain condition over the flow functions when using the on-demand supergraph.
    
    Also, it also ignores the type structure of the programming language. It can be used to kill facts due to impossible casts. Also, facts with the same variable but different types can be merged to one fact with the superclass as a type.

    The original definition starts the IFDS algorithm at the entry point of the interprocedural call-graph. As described, whenever needed a fact is derived from the zero fact. If the methods where initial facts will be introduced are known a priori, the supergraph can be traversed without applying flow functions until such a method is found on the path. This optimization introduces unbalanced problems where a method return is found but no corresponding call site which can be solved by a small extension to the tabulation algorithm. This was first described by Lerch and is also present in FlowDroid.     

    If the merge operator is set union, there is no need to wait for other predecessors to finish as a set is always a subset of a union with itself and another set ( holds) Is there a name for this property?. This allows the IFDS solver to skip the -set construction and immediately propagate the outcoming facts as singleton sets, which is beneficial in a parallelized solver.

    Access Paths    We have already seen IFDS fulfills context- and flow-sensitivity by default. A precise analysis for Java also needs object- and field-sensitivity. Thus, we also need to model the heap. Access paths are one possible heap model.

    Access paths are a list of field dereferences linked to a tainted variable of a reference type. Note, this increases the domain size because now not only "object  is tainted" is a data flow fact but also all of its fields can be tainted. This is especially a problem with recursive data structures which also allow recursive access paths such as linked lists. Consider lst:infiniteap, the loop would let the observed domain grow indefinitely and never reach a fixpoint.
    To guarantee a fixpoint, access paths are limited in length which is also called -limiting whereas the constant  is the maximum access path length. If an access path passes this length, it is cut off and the entire last reference is considered tainted. Consider again lst:infiniteap with . This time the analysis would reach the fixpoint  after two iterations.
    This obviously comes with a loss of precision but is inevitable.

    But -limiting on its own introduces a new problem. After a loop such as shown in lst:infiniteap, the access path is polluted with dereferences to itself even though the  dereference could be omitted without precision loss. Thus, Deutsch proposed symbolic access paths which try to eliminate loops in access paths. In practice, Deutschs approach needs some adaptions as he only considered fields but not base objects and he defines loops simply by type. 

    
                [b]0.45
                        max width=
                [gobble=20]
                    while (condition) 
                        lst = lst.next.prev;
                    
                                        Code
                        [b]0.45
                                    






                        Access Path Iterations
                Infinite Access Path
            
    Intermediate Representations    Most compiler these days use intermediate representations (IRs). IRs are an equivalent representation of the source code but are much simpler and more regular and are typically not architecture dependent. They are often in an interchangeable format and can be saved as text to be able to use them by a variety of tools.
    This allows compilers to apply machine-independent optimizations to the code with neither worrying about complex expressions in the source code nor reimplementing the optimization for each architecture. 

    The Java Virtual Machine (JVM) also operates on an IR called Java bytecode. The JVM is mostly stack-based and so is the Java bytecode. In lst:jvmstack is an example of a simple code snippet translated to Java bytecode. Simple expressions such as c = a + b are translated into multiple statements and there is no fixed length of an expression in the bytecode. The analysis would also have to reconstruct the expressions ad-hoc. Furthermore, Java bytecode has over 200 possible instructions(https://docs.oracle.com/javase/specs/jvms/se8/html/) which need to be taken into account and only knows primitive types and references. Concluding, stack-based IRs are suitable for just-in-time interpretation but inconvenient for data flow analysis.

    
                [b]0.45
                        [gobble=16]
                int a = 21;
                int b = 21;
                int c = a + b;
                        Java code
                                    [b]0.45
                        [gobble=16]
                bipush 21 // push 21
                istore_1  // store in register 1    
                bipush 21 // push 21
                istore_2 // store in register 2
                iload_1 // push a
                iload_2 // push b
                iadd // pop a & b and push a + b
                istore_3 // store in register 3
                        Java bytecode
                            Java bytecode example
            
    A more convenient representation for static analysis are three-address codes. Each statement consists of up to three operands and is either an assigment or a control-flow statement. Such a representation is closer to the original source code while reducing the number of the possible combinations to a managable amount.

    Jimple is a three-address intermediate representation and can be constructed from the Java and Dalvik bytecode, the IR used for Android apps. It is a high-level representation and its syntax is close to Java. Complex expressions are split up into multiple statements, for example, there can be only one field reference per statement and arguments are always local variables. Jimple also reconstructs reference types. This greatly reduces the possible cases the data flow analysis needs consider and eases the analyis.

    FlowDroid    
    Taken from https://developer.android.com/guide/components/activities/activity-lifecycle.
    
    FlowDroid is a precise context-, flow- and object-sensitive static taint analysis tool. It is based on Soot, a Java optimization framework, which later has been extended for static analysis. Soot provides the call graph and also the conversion from Java and Dalvik bytecode to Jimple, the intermediate representation FlowDroid works on.

    Androids activity-lifecycle concept shown in f:activity does not have a single entry point instead there are multiple callbacks. Also, an Android app can contain multiple components and can register callbacks in various of Android's standard library. FlowDroid models the entire Android lifecycle to be precise and generates a dummy main method to provide a single entry point for the call graph generation. It assumes multiple compontents can run in an arbitrary sequential order with repetitions.

    To provide precise results even with aliases, FlowDroid contains besides the taint analysis another IFDS problem to resolve all encountered aliases on-demand. For this, a high object-sensitivity is needed, hence it makes use of symbolic access paths is symbolic access paths right?.
    

    FlowDroid is implemented in a modular, easily extensible way and offers many additional features. Two of them are noteworthy for this work. First, the native call handler. As both, Java and Android, allow calling native methods, FlowDroid also needs to model those cases. It currently does not allow to analyze those methods but contains rules for important methods. The second are taint wrappers. They allow to define rules for methods, for example of a commonly used library, which allows the taint analysis to skip the method and just apply a summary. StubDroid, which is an extension to FlowDroid also by Arzt et al, allows to precompute summaries using FlowDroid and serialize them in an XML format for tool-independent use.
