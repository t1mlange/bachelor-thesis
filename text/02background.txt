
    Background    In this chapter, we introduce the necessary background.
    In s:dataflow, we explain the term static data flow analysis.
    We introduce concepts used to solve data flow problems precisely in s:bigifds and s:ap.
    We reason the need for a more manageable code representation in s:jimple.
    Finally, we introduce FlowDroid, the tool our work is based on, in s:flowdroid.

    Static Data Flow Analysis    In the field of compilers, there is a distinction between static and dynamic.
    Static generally refers to something that is decided at compile-time, while dynamic refers to runtime decisions.
    The same distinction is also present for analyses.
    Dynamic analysis observes the program's runtime behavior, while static analysis works on a representation of the code.
    Both have different tradeoffs.
    Achieving good code coverage is a challenge in dynamic analysis.
    In contrast, a static analysis often can not infer runtime properties, hence follows paths never taken at runtime, also called infeasible paths.
    Thus the dynamic analysis is an underapproximation and static analysis is an overapproximation.
    In the following, we only consider static analysis.

    Data flow analysis is a broad term for analyses that try to identify data flows through a program.
    Khedker defines data flow analysis as follows:
    
        Data flow analysis is a process of deriving information about the run time behavior of a program.
        Data flow analyses are used in many different ways.
    Compilers use it to apply optimizations, others use it for software verification and it is also used for reverse-engineering.
    A special kind of data flow analysis is taint analysis, which concepts might be familiar from code reviews.
    In taint analysis, the goal is to determine whether a particular variables' information contents flow through the program to another variable.
    Variables that contain valuable information are tainted.
    This valuable information has to come from somewhere, the so-called sources.
    Sources can be any expression but are often methods.
    Values produced from sources are considered tainted.
    On the other end, sinks leak valuable information.
    A data flow between a source and a sink is called a leak.
    For example, to detect apps tracking the user using taint analysis, sources could be methods returning a unique identifier and sinks could be methods that sent out data to the internet.
    When finding a leak, we know the receiving server can identify the device.

    There is also a categorization for data flow analyses.
    Sensitivities describe whether an analysis is capable of considering an aspect.
    There are five common sensitivities:
    
        Flow Sensitivity: A flow-sensitive analysis can determine if a fact holds at a particular statement.
        Context Sensitivity: An interprocedural analysis can distinguish the context of a called method, e.g., knows the original call site at a return statement.
        Object Sensitivity: An analysis can distinguish field accesses on different objects.
        Field Sensitivity: An analysis can distinguish different field accesses on the same object.
        Path Sensitivity: An analysis takes conditional branches into account, e.g., the condition holds after the branch.
    
    We also need a representation for the information the analysis gathered: the data flow fact.
    A data flow fact is a logical assertion that is either true or false at a statement.
    Now, there are two different kinds of facts: may and must.
    For a must analysis, the fact must hold on all paths to this statement, while a may analysis only guarantees the fact holds on one path.
    The decision of which kind fits depends on the type of data flow analysis.
    Taint analyses like FlowDroid are based on the may analysis.

    The analysis direction of a data flow analysis is also decided by the problem to be solved.
    A live variables analysis computes whether a variable is read before written in the future to eliminate potential dead assignments.
    A backward pass traditionally solves the problem.
    On the other hand, a reaching definitions analysis finds out if a definition reaches a statement without an intermediate assignment, usually solved by a forward pass.
    Additionally, there are also data flow analyses for which the direction is a design choice.
    For example, program slicing identifies a slice, a subset of the program's statements, which influence a statement (backward pass) or are influenced by a statement (forward pass).
    Taint analysis, on the other hand, can be solved in both directions with the same results.

    IFDS    Original Definition    Interprocedural finite distributive subset (IFDS) problems are a special class of a data flow analysis problem.
    Generally, the solution to a data flow problem is the meet-over-all-paths (MOP) solution, which is undecidable.
    However, all problems adhering to IFDS can be transformed into a graph-reachability problem and consequently, the solution is computable in polynomial time.
    It is context-sensitive and flow-sensitive by default.

    
    IFDS operates on a so-called exploded supergraph.
    Every node in the exploded supergraph is a tuple  of a statement  in the interprocedural control-flow graph and a data flow fact .
    The domain is typically the set of variables in the program.
    Edges between two nodes  and  exist if  propagated over  yields  and  is a successor of .
    Propagating facts along the control-flow graph already ensures flow-sensitivity.

    
                max width=
            [basicstyle=, mathescape, gobble=16, numbers=none,literate=->2]
                matched -> ( matched ) matched  
                valid -> valid ( matched  matched
                            Context-Free Grammar proposed by Reps et al.
            
    
    To achieve context-sensitivity, Reps et al. proposed a context-free grammar (c.f. lst:cfl).
    Each call site gets a unique index, outgoing call edges are labeled with  and incoming return edges are labeled with .
    matched ensures the correct return edge is taken and valid models a partially balanced path, e.g., after a call for which the return is still pending.
    A path between two nodes is called valid if the sequence of labeled edges is a string in valid.
    Consider the example in tikz:context.
    After the first call to bar, the sequence is , which is in valid.
    Now, there are multiple return edges from bar but only  is in matched.
    Thus, only the  edge is taken.
    MOP with this context-free language is also called meet-over-all-valid-paths (MOVP). MOVP increases the precision but does not compromise soundness ().
    Still, the valid paths are an overapproximation because they also contain infeasible paths.

    
                
        Context-Sensitivity using a Context-Free Language
            
    
    To propagate facts over statements, we need to define rules on how the data flow changes when observing a statement.
    These rules are called flow functions.
    There are four types of flow functions:    
        Call Flow: Edges from call statement into a method. The flow function maps the facts visible in the callee into it.
        Return Flow: Edges returning from a method. The flow function maps the facts visible in the caller out of the callee.
        Call To Return Flow: Edges over a call statement. The flow function maps the facts not visible in the callee over the call statement.
        Normal Flow: The default case. Handles edges over every other statement, for example, assignments.
        The incoming set of facts is all predecessors' outgoing facts merged using a merge operator :
    


    
    Now, we also want to introduce new facts.
    For that reason, the domain contains a zero fact and all nodes with  are always reachable; thus, the zero fact is a tautology.
    Whenever we want to introduce a fact, we can model this in the flow function by deriving such facts from the zero fact .
    For example, in taint analysis, the flow functions map zero facts at sources to a tainted variable.

    
    IFDS also utilizes summaries.
    After returning from a method, the algorithm solved a subproblem for which it remembers the results to be applied later.
    So, the proposed tabulation algorithm for solving the realizable path problem is a dynamic algorithm.

    
    Eventually, the worklist is empty as there are no facts to propagate anymore and the analysis will terminate.
    There are two ways for a fact to be not propagated further.
    Either a flow function killed the fact or the same fact was already observed at a statement, meaning the IFDS analysis reached a fixpoint.

    However, we already started this section, hinting not all problems can be formulated in the IFDS framework.
    The restrictions the problems have to abide by are eponymous in IFDS and explained in the following paragraphs.

    Distributive The flow function must be distributive over the merge operator.
    Formally,  must hold at any time.
    Informally speaking, it does not matter whether facts get merged before or after applying the flow functions.
    Distributiveness is essential for the correctness of IFDS because only if the flow functions are distributive, the maximum fixed point (MFP) equals MOP and MFP is computable in polynomial time.

    Finite Another restriction is that the set of data flow facts has to be finite.
    Let us go by a counterexample of what IFDS is not capable of: Answering "Which value is stored in variable x at statement s?".
    Now the data flow fact is a tuple of the variable together with the stored value .
    Consider lst:ifdsfinite.
     is initialized to an empty string and in every loop iteration, a gets appended to the string.
    The value of x changes every time and never repeats itself.
    In theory, the algorithm will never observe a taint twice in line 4.
    Because the algorithm can not reach a fixpoint, it will not terminate.
    In practice, every data type is bounded either by the heap or stack size, but the domain is cubic in the time-complexity  making IFDS infeasible for large domains.

    
                [b]0.45
                        max width=
                [gobble=20]
                    void main() 
                        String x = "";
                        while (condition)
                            x += "a";
                    
                                        Code
                        [b]0.45
                        







            Taint Derivations
                            Finiteness example
            
    Subset Data flow frameworks need to deal with merging the outcoming sets to a single incoming set.
    Essentially, to formalize the approximation and satisfy ordering constraints, data flow frameworks rely on lattices.
    IFDS also defines an underlying lattice on the powerset of the domain.
    The lattice ordering must be set inclusion.
    Therefore, the merge operator is set union or set intersect.
    Now recall may and must from [s:dataflow]the last subsection.
    Here we can see the connection between the merge operator and may or must.

    The paper by Reps et al. later decides on set union due to the duality of must and may not.
    This decision is also efficient in practice, as discussed in the [s:ifdspractical]following subsection.


    Practical Extensions    The original definition is inefficient in practice.
    Among others, Naeem et al. proposed practical extensions to the IFDS framework to perform better in practice.

    The original algorithm demands a fully built exploded supergraph.
    Even in moderate programs, the domain can get quite large.
    As the nodes in the exploded supergraph are the cross-product of the domain and interprocedural call-graph nodes, it is infeasible to generate the full graph beforehand.
    Because there is no way to know before which part of the supergraph the analysis demands, they propose to generate it ad-hoc.
    That also removes the restriction on a small domain.
    Now IFDS is also feasible if the domain's encountered subset is small enough.
    The restrictions on the domain set can be loosened even more.
    Bodden suggests the domain can be infinite in practice.
    Only the observed facts must adhere to the ascending-chain condition over the flow functions when using the on-demand supergraph.

    Also, the original IFDS definition ignores the type structure of the programming language.
    Type information can be used to kill facts due to impossible casts.
    Also, facts with the same variable but different types can be merged with the superclass as its new type.

    Furthermore, the original definition starts the IFDS algorithm at the entry point of the interprocedural call-graph.
    As described in s:ifds, a flow function can derive an initial fact from the zero fact if needed.
    If the methods where initial facts will be introduced are known a priori, the supergraph can be traversed without applying flow functions until such a method is found on the path.
    This optimization introduces unbalanced problems where a method returns but no corresponding call site is found, which can be solved by a small extension to the tabulation algorithm.
    Lerch et al. first described the extension and it is also present in FlowDroid.

    Another optimization is possible if the merge operator is set union thanks to the  property of set union.
    There is no need to wait for other predecessors to finish as a set is always a subset of a union with itself and another set.
    Hence, the IFDS solver can skip the -set construction and immediately propagate the outcoming facts as singleton sets, sometimes referred to as point-wise propagation.
    Especially parallelized IFDS implementations benefit from point-wise propagation.

    Access Paths    We have already seen IFDS fulfills context- and flow-sensitivity by default.
    Now, a precise analysis for Java also needs object- and field-sensitivity.
    Thus, we also need to model the heap.

    Access paths are one possible heap model.
    They consist of a list of field dereferences linked to a tainted variable of a reference type.
    Note, this increases the domain size because now not only "object  is tainted" is a data flow fact, but also all of its fields can be tainted.
    Especially when encountering recursive data structures with loops such as doubly-linked lists, this gets problematical.
    Consider lst:infiniteap, the loop would let the observed domain grow indefinitely and never reach a fixpoint.
    As a solution, access paths are limited in length, which is also called -limiting, whereas the constant  is the maximum access path length.
    If an access path passes this length, it is cut off and the entire last reference is considered tainted.
    This cut-off comes with a loss of precision.
    Consider again lst:infiniteap.
    With  the analysis would reach the fixpoint  after two iterations.

    
                [b]0.45
                        max width=
                [gobble=20]
                    while (condition) 
                        lst = lst.next.prev;
                    
                                        Code
                        [b]0.45
                                    






                        Access Path Iterations
                Infinite Access Path
            
    Although with -limiting, the algorithm terminates, it does have another problem.
    After a loop like in lst:infiniteap, the access path is polluted with a dereference chain to its base object even though the  dereference could be omitted without precision loss.
    As a solution, Deutsch proposed symbolic access paths, which try to eliminate loops in access paths.
    In practice, Deutsch's approach needs some adaptions as he only considered fields but not base objects and he defines loops simply by type.
    With symbolic access paths -limiting is theoretically obsolete but still often applied to speed up the analysis.

    Intermediate Representations    Most compilers these days use intermediate representations (IRs).
    IRs are an equivalent representation of the source code but are less complex and more regular and are typically not architecture-dependent.
    They are often in an interchangeable format and can be saved as text to be used by various tools.
    Such an IR allows compilers to apply machine-independent optimizations to the code without worrying about complex expressions in the source code or reimplementing the optimization for each architecture.

    The Java Virtual Machine (JVM) also operates on an IR called Java bytecode.
    The JVM is mostly stack-based and so is the Java bytecode.
    In lst:jvmstack is an example of a simple code snippet translated to Java bytecode.
    Simple expressions such as c = a + b translate into multiple statements and there is no fixed length of an expression in the bytecode.
    The analysis would also have to reconstruct the expressions ad-hoc.
    Furthermore, Java bytecode has over 200 possible instructions, which need to be considered and only knows primitive types and references.
    Concluding, stack-based IRs are suitable for just-in-time interpretation but inconvenient for data flow analysis.
    Source: https://docs.oracle.com/javase/specs/jvms/se8/html/ (visited on 17.04.2021)

    
                [b]0.45
                        [gobble=16]
                int a = 21;
                int b = 21;
                int c = a + b;
                        Java code
                                    [b]0.45
                        [gobble=16]
                bipush 21 // push 21
                istore_1  // store in register 1
                bipush 21 // push 21
                istore_2 // store in register 2
                iload_1 // push a
                iload_2 // push b
                iadd // pop a & b and push a + b
                istore_3 // store in register 3
                        Java bytecode
                            Java bytecode example
            
    A more convenient representation for static analysis is three-address codes.
    Each statement consists of up to three operands and is either an assignment or a control-flow statement.
    Operands are represented by variables instead of registers or stacks.
    Such a representation fixes the expression length to be better suited for static analysis than assembly. It also reduces the possible combinations to a manageable amount compared to the source code written by a human.

    Jimple is a three-address intermediate representation and can be constructed from the Java and Dalvik bytecode, the IR used for Android apps.
    It is a high-level representation and its syntax is close to Java.
    Complex statements are split up into multiple statements.
    For example, there can be only one field reference per statement and arguments are always local variables or constants.
    This groundwork dramatically reduces the possible cases the data flow analysis needs to consider and eases the analysis.

    FlowDroid    FlowDroid is a precise context-, flow-, object- and field-sensitive static taint analysis tool for Android apps.
    Since its initial release in 2014, it is actively maintained and gained traction in research and academia.
    It is based on Soot, a Java optimization framework, which later has been extended for static analysis.
    Soot provides the call graph and the conversion from Java and Dalvik bytecode to Jimple, the intermediate representation of choice for FlowDroid.
    Source: https://github.com/secure-software-engineering/FlowDroid (visited on 17.04.2021)

    Androids activity-lifecycle concept does not have a single entry point; instead, multiple callbacks are a possible entry point.
    Also, an Android app can contain multiple components and register callbacks in various of Android's standard libraries.
    FlowDroid models the entire Android lifecycle to be precise and generates a dummy main method to provide a single entry point for the call graph generation.
   .

    
                        Activity Lifecycle
                Source: https://developer.android.com/guide/components/activities/activity-lifecycle (visited on 17.04.2021)

    FlowDroid inherits flow- and context-sensitivity from IFDS and the object- and field-sensitivity from symbolic access paths. To provide precise results even with aliases in use, FlowDroid comprises an alais analysis. The alias analysis is encoded as another IFDS problem and resolves all encountered aliases on-demand. The two IFDS analyses are intertwined to maintain flow- and context-sensitivity between both analyses.

    The implementation of FlowDroid is modular, easily extensible and offers many additional features.
    Two of them are noteworthy for this work: native call handler and taint wrappers.
    As both Java and Android allow calling native methods, FlowDroid also needs to model those cases.
    It currently does not support the analysis of those methods but contains rules for essential methods.
    The second feature is taint wrappers.
    They allow defining rules for methods, e.g., from a commonly used feature such as StringBuilder, which allows the taint analysis to skip the method and apply a summary.
    StubDroid, an extension to FlowDroid by Arzt et al., allows precomputing summaries using FlowDroid and serializes them in an XML format for tool-independent use.
    These summaries are handy for real-world applications where third-party libraries are often used.
