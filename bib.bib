% Encoding: UTF-8

@InProceedings{NguyenQuangDo2017,
  author   = {Nguyen Quang Do, Lisa and Ali, Karim and Livshits, Benjamin and Bodden, Eric and Smith, Justin and Murphy-Hill, Emerson},
  title    = {Just-in-time static analysis},
  year     = {2017},
  month    = jul,
  pages    = {307--317},
  abstract = {We present the concept of Just-In-Time (JIT) static analysis that interleaves code development and bug fixing in an integrated development environment. Unlike traditional batch-style analysis tools, a JIT analysis tool presents warnings to code developers over time, providing the most relevant results quickly, and computing less relevant results incrementally later. In this paper, we describe general guidelines for designing JIT analyses. We also present a general recipe for transforming static data-flow analyses to JIT analyses through a concept of layered analysis execution. We illustrate this transformation through CHEETAH, a JIT taint analysis for Android applications. Our empirical evaluation of CHEETAH on real-world applications shows that our approach returns warnings quickly enough to avoid disrupting the normal workflow of developers. This result is confirmed by our user study, in which developers fixed data leaks twice as fast when using CHEETAH compared to an equivalent batch-style analysis.},
  doi      = {10.1145/3092703.3092705},
  file     = {Full Text PDF:https\://www.researchgate.net/profile/Justin-Smith-55/publication/318375338_Just-in-time_static_analysis/links/59f75092a6fdcc075ec7b0ef/Just-in-time-static-analysis.pdf:application/pdf;ResearchGate Link:https\://www.researchgate.net/publication/318375338_Just-in-time_static_analysis:},
}

@InProceedings{Tripp2013,
  author     = {Tripp, Omer and Pistoia, Marco and Cousot, Patrick and Cousot, Radhia and Guarnieri, Salvatore},
  booktitle  = {Fundamental {Approaches} to {Software} {Engineering}},
  title      = {Andromeda: {Accurate} and {Scalable} {Security} {Analysis} of {Web} {Applications}},
  year       = {2013},
  address    = {Berlin, Heidelberg},
  editor     = {Cortellessa, Vittorio and Varró, Dániel},
  pages      = {210--225},
  publisher  = {Springer},
  series     = {Lecture {Notes} in {Computer} {Science}},
  abstract   = {Security auditing of industry-scale software systems mandates automation. Static taint analysis enables deep and exhaustive tracking of suspicious data flows for detection of potential leakage and integrity violations, such as cross-site scripting (XSS), SQL injection (SQLi) and log forging. Research in this area has taken two directions: program slicing and type systems. Both of these approaches suffer from a high rate of false findings, which limits the usability of analysis tools based on these techniques. Attempts to reduce the number of false findings have resulted in analyses that are either (i) unsound, suffering from the dual problem of false negatives, or (ii) too expensive due to their high precision, thereby failing to scale to real-world applications.In this paper, we investigate a novel approach for enabling precise yet scalable static taint analysis. The key observation informing our approach is that taint analysis is a demand-driven problem, which enables lazy computation of vulnerable information flows, instead of eagerly computing a complete data-flow solution, which is the reason for the traditional dichotomy between scalability and precision. We have implemented our approach in Andromeda, an analysis tool that computes data-flow propagations on demand, in an efficient and accurate manner, and additionally features incremental analysis capabilities. Andromeda is currently in use in a commercial product. It supports applications written in Java, .NET and JavaScript. Our extensive evaluation of Andromeda on a suite of 16 production-level benchmarks shows Andromeda to achieve high accuracy and compare favorably to a state-of-the-art tool that trades soundness for precision.},
  doi        = {10.1007/978-3-642-37057-1_15},
  file       = {Springer Full Text PDF:https\://link.springer.com/content/pdf/10.1007%2F978-3-642-37057-1_15.pdf:application/pdf},
  isbn       = {9783642370571},
  keywords   = {Security , Static Analysis , Taint Analysis , Information Flow , Integrity , Abstract Interpretation },
  language   = {en},
  shorttitle = {Andromeda},
}

@Article{Allen2021,
  author   = {Allen, Nicholas and Gauthier, François and Jordan, Alexander},
  journal  = {arXiv:2103.16240 [cs]},
  title    = {{IFDS} {Taint} {Analysis} with {Access} {Paths}},
  year     = {2021},
  month    = mar,
  note     = {arXiv: 2103.16240},
  abstract = {Over the years, static taint analysis emerged as the analysis of choice to detect some of the most common web application vulnerabilities, such as SQL injection (SQLi) and cross-site scripting (XSS){\textasciitilde}{\textbackslash}cite\{OWASP\}. Furthermore, from an implementation perspective, the IFDS dataflow framework stood out as one of the most successful vehicles to implement static taint analysis for real-world Java applications. While existing approaches scale reasonably to medium-size applications (e.g. up to one hour analysis time for less than 100K lines of code), our experience suggests that no existing solution can scale to very large industrial code bases (e.g. more than 1M lines of code). In this paper, we present our novel IFDS-based solution to perform fast and precise static taint analysis of very large industrial Java web applications. Similar to state-of-the-art approaches to taint analysis, our IFDS-based taint analysis uses {\textbackslash}textit\{access paths\} to abstract objects and fields in a program. However, contrary to existing approaches, our analysis is demand-driven, which restricts the amount of code to be analyzed, and does not rely on a computationally expensive alias analysis, thereby significantly improving scalability.},
  file     = {arXiv Fulltext PDF:https\://arxiv.org/pdf/2103.16240.pdf:application/pdf},
  keywords = {Computer Science - Programming Languages, Computer Science - Software Engineering},
  url      = {http://arxiv.org/abs/2103.16240},
  urldate  = {2021-04-14},
}

@InProceedings{Arzt2016,
  author     = {Arzt, Steven and Bodden, Eric},
  title      = {{StubDroid}: automatic inference of precise data-flow summaries for the android framework},
  year       = {2016},
  month      = may,
  pages      = {725--735},
  abstract   = {Smartphone users suffer from insufficient information on how commercial as well as malicious apps handle sensitive data stored on their phones. Automated taint analyses address this problem by allowing users to detect and investigate how applications access and handle this data. A current problem with virtually all those analysis approaches is, though, that they rely on explicit models of the Android runtime library. In most cases, the existence of those models is taken for granted, despite the fact that the models are hard to come by: Given the size and evolution speed of a modern smartphone operating system it is prohibitively expensive to derive models manually from code or documentation.
In this work, we therefore present StubDroid, the first fully automated approach for inferring precise and efficient library models for taint-analysis problems. StubDroid automatically constructs these summaries from a binary distribution of the library. In our experiments, we use StubDroid-inferred models to prevent the static taint analysis FlowDroid from having to re-analyze the Android runtime library over and over again for each analyzed app. As the results show, the models make it possible to analyze apps in seconds whereas most complete re-analyses would time out after 30 minutes. Yet, StubDroid yields comparable precision. In comparison to manually crafted summaries, StubDroid's cause the analysis to be more precise and to use less time and memory.},
  doi        = {10.1145/2884781.2884816},
  file       = {ResearchGate Link:https\://www.researchgate.net/publication/303099519_StubDroid_automatic_inference_of_precise_data-flow_summaries_for_the_android_framework:},
  shorttitle = {{StubDroid}},
}

@InProceedings{Titze2015,
  author     = {Titze, D. and Schütte, J.},
  booktitle  = {2015 {IEEE} 29th {International} {Conference} on {Advanced} {Information} {Networking} and {Applications}},
  title      = {Apparecium: {Revealing} {Data} {Flows} in {Android} {Applications}},
  year       = {2015},
  month      = mar,
  note       = {ISSN: 2332-5658},
  pages      = {579--586},
  abstract   = {With Android applications processing not only personal but also business-critical data, efficient and precise data flow analysis has become a major technique to detect apps handling critical data in unwanted ways. Although data flow analysis in general is a thoroughly researched topic, the event-driven lifecycle model of Android has its own challenges and practical application requires for reliable and efficient analysis techniques. In this paper we present Apparecium, a tool to reveal data flows in Android applications. Apparecium has conceptual differences to other techniques, and can be used to find arbitrary data flows inside Android applications. Details about the used techniques and the differences to existing data flow analysis tools are presented, as well as an evaluation against the data flow analysis framework Flow Droid.},
  doi        = {10.1109/AINA.2015.239},
  file       = {IEEE Xplore Full Text PDF:https\://ieeexplore.ieee.org/stampPDF/getPDF.jsp?tp=&arnumber=7098024&ref=aHR0cHM6Ly9pZWVleHBsb3JlLmllZWUub3JnL2RvY3VtZW50LzcwOTgwMjQ=:application/pdf},
  issn       = {2332-5658},
  keywords   = {Androids, Humanoid robots, Algorithm design and analysis, Sockets, Writing, Radiation detectors, Input variables, Android, Static Data Flow Analysis},
  shorttitle = {Apparecium},
}

@InProceedings{Ferrara2020,
  author     = {Ferrara, Pietro and Olivieri, Luca and Spoto, Fausto},
  booktitle  = {Verification, {Model} {Checking}, and {Abstract} {Interpretation}},
  title      = {BackFlow: {Backward} {Context}-{Sensitive} {Flow} {Reconstruction} of {Taint} {Analysis} {Results}},
  year       = {2020},
  address    = {Cham},
  editor     = {Beyer, Dirk and Zufferey, Damien},
  pages      = {23--43},
  publisher  = {Springer International Publishing},
  series     = {Lecture {Notes} in {Computer} {Science}},
  abstract   = {Taint analysis detects if data coming from a source, such as user input, flows into a sink, such as an SQL query, unsanitized (not properly escaped). Both static and dynamic taint analyses have been widely applied to detect injection vulnerabilities in real world software. A main drawback of static analysis is that it could produce false alarms. In addition, it is extremely time-consuming to manually explain the flow of tainted data from the results of the analysis, to understand why a specific warning was raised. This paper formalizes BackFlowBackFlow{\textbackslash}mathsf \{BackFlow\}, a context-sensitive taint flow reconstructor that, starting from the results of a taint-analysis engine, reconstructs how tainted data flows inside the program and builds paths connecting sources to sinks. BackFlowBackFlow{\textbackslash}mathsf \{BackFlow\} has been implemented on Julia’s static taint analysis. Experimental results on a set of standard benchmarks show that, when BackFlowBackFlow{\textbackslash}mathsf \{BackFlow\} produces a taint graph for an injection warning, then there is empirical evidence that such warning is a true alarm. Moreover BackFlowBackFlow{\textbackslash}mathsf \{BackFlow\} scales to real world programs.},
  doi        = {10.1007/978-3-030-39322-9_2},
  file       = {Springer Full Text PDF:https\://link.springer.com/content/pdf/10.1007%2F978-3-030-39322-9_2.pdf:application/pdf},
  isbn       = {9783030393229},
  language   = {en},
  shorttitle = {\$\${\textbackslash}mathsf \{{BackFlow}\}\$\$},
}

@Article{Grech2017,
  author     = {Grech, Neville and Smaragdakis, Yannis},
  journal    = {Proceedings of the ACM on Programming Languages},
  title      = {P/{Taint}: unified points-to and taint analysis},
  year       = {2017},
  month      = oct,
  pages      = {1--28},
  volume     = {1},
  abstract   = {Static information-flow analysis (especially taint-analysis) is a key technique in software security, computing where sensitive or untrusted data can propagate in a program. Points-to analysis is a fundamental static program analysis, computing what abstract objects a program expression may point to. In this work, we propose a deep unification of information-flow and points-to analysis. We observe that information-flow analysis is not a mere high-level client of points-to information, but it is indeed identical to points-to analysis on artificial abstract objects that represent different information sources. The very same algorithm can compute, simultaneously, two interlinked but separate results (points-to and information-flow values) with changes only to its initial conditions.
The benefits of such a unification are manifold. We can use existing points-to analysis implementations, with virtually no modification (only minor additions of extra logic for sanitization) to compute information flow concepts, such as value tainting. The algorithmic enhancements of points-to analysis (e.g., different flavors of context sensitivity) can be applied transparently to information-flow analysis. Heavy engineering work on points-to analysis (e.g., handling of the reflection API for Java) applies to information-flow analysis without extra effort. We demonstrate the benefits in a realistic implementation that leverages the Doop points-to analysis framework (including its context-sensitivity and reflection analysis features) to provide an information-flow analysis with excellent precision (over 91\%) and recall (over 99\%) for standard Java information-flow benchmarks.
The analysis comfortably scales to large, real-world Android applications, analyzing the Facebook Messenger app with more than 55K classes in under 7 hours.},
  doi        = {10.1145/3133926},
  file       = {ResearchGate Link:https\://www.researchgate.net/publication/320390381_PTaint_unified_points-to_and_taint_analysis:},
  shorttitle = {P/{Taint}},
}

@Article{Lerch2014,
  author     = {Lerch, J. and Hermann, Ben and Bodden, E. and Mezini, M.},
  journal    = {SIGSOFT FSE},
  title      = {{FlowTwist}: efficient context-sensitive inside-out taint analysis for large codebases},
  year       = {2014},
  abstract   = {Over the past years, widely used platforms such as the Java Class Library have been under constant attack through vulnerabilities that involve a combination of two taint-analysis problems: an integrity problem allowing attackers to trigger sensitive operations within the platform, and a confidentiality problem allowing the attacker to retrieve sensitive information or pointers from the results of those operations. While existing static taint analyses are good at solving either of those problems, we show that they scale prohibitively badly when being applied to situations that require the exploitation of both an integrity and confidentiality problem in combination. The main problem is the huge attack surface of libraries such as the Java Class Library, which exposes thousands of methods potentially controllable by an attacker. In this work we thus present FlowTwist, a novel taint-analysis approach that works inside-out, i.e., tracks data flows from potentially vulnerable calls to the outer level of the API which the attacker might control. This inside-out analysis requires a careful, context-sensitive coordination of both a backward and a forward taint analysis. In this work, we expose a design of the analysis approach based on the IFDS algorithm, and explain several extensions to IFDS that enable not only this coordination but also a helpful reporting of error situations to security analysts. Experiments with the Java Class Library show that, while a simple forward taint-analysis approach does not scale even with much machine power, FlowTwist's algorithm is able to fully analyze the library within 10 minutes.},
  doi        = {10.1145/2635868.2635878},
  file       = {Semantic Scholar Link:https\://www.semanticscholar.org/paper/FlowTwist%3A-efficient-context-sensitive-inside-out-Lerch-Hermann/28f538ccabcc9edbbf27d0f0a027031615936e42:text/html},
  shorttitle = {{FlowTwist}},
}

@Article{Rice1953,
  author   = {Rice, H.},
  title    = {Classes of recursively enumerable sets and their decision problems},
  year     = {1953},
  abstract = {1. Introduction. In this paper we consider classes whose elements are re-cursively enumerable sets of non-negative integers. No discussion of recur-sively enumerable sets can avoid the use of such classes, so that it seems desirable to know some of their properties. We give our attention here to the properties of complete recursive enumerability and complete recursiveness (which may be intuitively interpreted as decidability). Perhaps our most interesting result (and the one which gives this paper its name) is the fact that no nontrivial class is completely recursive. We assume familiarity with a paper of Kleene [5](2), and with ideas which are well summarized in the first sections of a paper of Post Í7].},
  doi      = {10.1090/S0002-9947-1953-0053041-6},
  file     = {Semantic Scholar Link:https\://www.semanticscholar.org/paper/Classes-of-recursively-enumerable-sets-and-their-Rice/664a7d3c60b753a34f1601a7378ca952ea92e9a8:text/html;Full Text PDF:https\://pdfs.semanticscholar.org/664a/7d3c60b753a34f1601a7378ca952ea92e9a8.pdf:application/pdf},
}

@InProceedings{Rodriguez2011,
  author    = {Rodriguez, Jonathan and Lhoták, Ondřej},
  booktitle = {Compiler {Construction}},
  title     = {Actor-{Based} {Parallel} {Dataflow} {Analysis}},
  year      = {2011},
  address   = {Berlin, Heidelberg},
  editor    = {Knoop, Jens},
  pages     = {179--197},
  publisher = {Springer},
  series    = {Lecture {Notes} in {Computer} {Science}},
  abstract  = {Defining algorithms in a way which allows parallel execution is becoming increasingly important as multicore computers become ubiquitous. We present IFDS-A, a parallel algorithm for solving context-sensitive interprocedural finite distributive subset (IFDS) dataflow problems. IFDS-A defines these problems in terms of Actors, and dataflow dependencies as messages passed between these Actors. We implement the algorithm in Scala, and evaluate its performance against a comparable sequential algorithm. With eight cores, IFDS-A is 6.12 times as fast as with one core, and 3.35 times as fast as a baseline sequential algorithm. We also found that Scala’s default Actors implementation is not optimal for this algorithm, and that a custom-built implementation outperforms it by a significant margin. We conclude that Actors are an effective way to parallelize this type of algorithm.},
  doi       = {10.1007/978-3-642-19861-8_11},
  file      = {Springer Full Text PDF:https\://link.springer.com/content/pdf/10.1007%2F978-3-642-19861-8_11.pdf:application/pdf},
  isbn      = {9783642198618},
  keywords  = {Actors , compilers , concurrency , dataflow analysis , IFDS , Scala },
  language  = {en},
}

@InProceedings{Deutsch1994,
  author     = {Deutsch, A.},
  booktitle  = {{PLDI} '94},
  title      = {Interprocedural may-alias analysis for pointers: beyond k-limiting},
  year       = {1994},
  abstract   = {Existing methods for alias analysis of recursive pointer data structures are based on two approximation techniques: k-limiting, and store-based (or equivalently location or region-based) approximations, which blur distinction between elements of recursive data structures. Although notable progress in inter-procedural alias analysis has been recently accomplished, very little progress in the precision of analysis of recursive pointer data structures has been seen since the inception of these approximation techniques by Jones and Muchnick a decade ago. As a result, optimizing, verifying and parallelizing programs with pointers has remained difficult.
We present a new parametric framework for analyzing recursive pointer data structures which can express a new natural class of alias information not accessible to existing methods. The key idea is to represent alias information by pairs of symbolic access paths which are qualified by symbolic descriptions of the positions for which the alias pair holds.
Based on this result, we present an algorithm for interprocedural may-alias analysis with pointers which on numerous examples that occur in practice is much more precise than recently published algorithms [CWZ90, He90, LR92, CBC93].},
  doi        = {10.1145/178243.178263},
  file       = {Semantic Scholar Link:https\://www.semanticscholar.org/paper/Interprocedural-may-alias-analysis-for-pointers%3A-Deutsch/7ff982c9608cfab62c4c5c1a65ad737dae3ab0f8:text/html},
  shorttitle = {Interprocedural may-alias analysis for pointers},
}

@Article{Spaeth2019,
  author   = {Späth, Johannes and Ali, Karim and Bodden, Eric},
  journal  = {Proceedings of the ACM on Programming Languages},
  title    = {Context-, flow-, and field-sensitive data-flow analysis using synchronized {Pushdown} systems},
  year     = {2019},
  month    = jan,
  pages    = {1--29},
  volume   = {3},
  abstract = {Precise static analyses are context-, field- and flow-sensitive. Context- and field-sensitivity are both expressible as context-free language (CFL) reachability problems. Solving both CFL problems along the same data-flow path is undecidable, which is why most flow-sensitive data-flow analyses over-approximate field-sensitivity through k-limited access-path, or through access graphs. Unfortunately, as our experience and this paper show, both representations do not scale very well when used to analyze programs with recursive data structures.
Any single CFL-reachability problem is efficiently solvable, by means of a pushdown system. This work thus introduces the concept of synchronized pushdown systems (SPDS). SPDS encode both procedure calls/returns and field stores/loads as separate but “synchronized” CFL reachability problems. An SPDS solves both individual problems precisely, and approximation occurs only in corner cases that are apparently rare in practice: at statements where both problems are satisfied but not along the same data-flow path.
SPDS are also efficient: formal complexity analysis shows that SPDS shift the complexity from {\textbar}F{\textbar}3k under k-limiting to {\textbar}S{\textbar}{\textbar}F{\textbar}², where F is the set of fields and S the set of statements involved in a data-flow. Our evaluation using DaCapo shows this shift to pay off in practice: SPDS are almost as efficient as k-limiting with k=1 although their precision equals k=∞. For a typestate analysis SPDS accelerate the analysis up to 83× for data-flows of objects that involve many field accesses but span rather few methods.
We conclude that SPDS can provide high precision and further improve scalability, in particularly when used in analyses that expose rather local data flows.},
  doi      = {10.1145/3290361},
  file     = {ResearchGate Link:https\://www.researchgate.net/publication/330152854_Context-_flow-_and_field-sensitive_data-flow_analysis_using_synchronized_Pushdown_systems:},
}

@InProceedings{Lam2011,
  author     = {Lam, Patrick and Bodden, Eric and Lhotak, Ondrej and Hendren, Laurie},
  title      = {The {Soot} framework for {Java} program analysis: a retrospective},
  year       = {2011},
  month      = oct,
  language   = {en},
  shorttitle = {The {Soot} framework for {Java} program analysis},
  url        = {http://www.bodden.de/pubs/lblh11soot.pdf},
  urldate    = {2021-03-11},
}

@InProceedings{Rasthofer2014,
  author    = {Rasthofer, Siegfried and Arzt, Steven and Bodden, E.},
  booktitle = {{NDSS}},
  title     = {A {Machine}-learning {Approach} for {Classifying} and {Categorizing} {Android} {Sources} and {Sinks}},
  year      = {2014},
  abstract  = {Today’s smartphone users face a security dilemma: many apps they install operate on privacy-sensitive data, although 
they might originate from developers whose trustworthiness is hard to judge. Researchers have addressed the problem with more and more sophisticated static and dynamic analysis tools as an aid to assess how apps use private user data. Those tools, however, rely on the manual configuration of lists of sources of sensitive data as well as sinks which might leak data to untrusted observers. Such lists are hard to come by. 
 
We thus propose SUSI, a novel machine-learning guided approach for identifying sources and sinks directly from the code of any Android API. Given a training set of hand-annotated sources and sinks, SUSI identifies other sources and sinks in the entire API. To provide more fine-grained information, SUSI further categorizes the sources (e.g., unique identifier, location information, etc.) and sinks (e.g., network, file, etc.). 
 
For Android 4.2, SUSI identifies hundreds of sources and sinks with over 92\% accuracy, many of which are missed by current information-flow tracking tools. An evaluation of about 11,000 malware samples confirms that many of these sources and sinks are indeed used. We furthermore show that SUSI can reliably classify sources and sinks even in new, previously unseen Android versions and components like Google Glass or the Chromecast API.},
  doi       = {10.14722/NDSS.2014.23039},
  file      = {Semantic Scholar Link:https\://www.semanticscholar.org/paper/A-Machine-learning-Approach-for-Classifying-and-and-Rasthofer-Arzt/33987e58b45755a6120905ce582fc9cbec434763:text/html;Full Text PDF:https\://pdfs.semanticscholar.org/5a8e/d3604393818fe1bca9396e55ea6bd320e49c.pdf:application/pdf},
}

@Book{Aho1986,
  author       = {Aho, Alfred V. and Sethi, Ravi and Ullman, Jeffrey D.},
  publisher    = {Reading, Mass. : Addison-Wesley Pub. Co.},
  title        = {Compilers, principles, techniques, and tools},
  year         = {1986},
  isbn         = {9780201100884},
  abstract     = {Bibliography: p. [752]-779; Includes index},
  collaborator = {{Internet Archive}},
  keywords     = {Compilers (Computer programs)},
  language     = {eng},
  url          = {http://archive.org/details/compilersprincip00ahoa},
  urldate      = {2021-02-15},
}

@Book{Thain2019,
  author    = {Thain, Douglas},
  publisher = {Lulu.com},
  title     = {Introduction to {Compilers} and {Language} {Design}},
  year      = {2019},
  isbn      = {9780359138043},
  month     = jul,
  note      = {Google-Books-ID: 5mVyDwAAQBAJ},
  abstract  = {A compiler translates a program written in a high level language into a program written in a lower level language. For students of computer science, building a compiler from scratch is a rite of passage: a challenging and fun project that offers insight into many different aspects of computer science, some deeply theoretical, and others highly practical. This book offers a one semester introduction into compiler construction, enabling the reader to build a simple compiler that accepts a C-like language and translates it into working X86 or ARM assembly language. It is most suitable for undergraduate students who have some experience programming in C, and have taken courses in data structures and computer architecture.},
  file      = {Google Books Link:https\://books.google.de/books?id=5mVyDwAAQBAJ:text/html},
  keywords  = {Computers / General},
  language  = {en},
}

@PhdThesis{Arzt2017PhD,
  author    = {Arzt, Steven},
  school    = {Technische Universität},
  title     = {Static {Data} {Flow} {Analysis} for {Android} {Applications}},
  year      = {2017},
  address   = {Darmstadt},
  abstract  = {Mobile phones have become important daily companions for millions of people which help to organize both their private and their professional lives. Having access to data such as the calendar or the address book anywhere, anytime, has become commonplace. Sensor data such as the phone's GPS location and accelerometer help users navigate through the physical world. Users can furthermore extend the functionality of their phone using small programs called apps from various developers and vendors in an open ecosystem. Undoubtedly, having all this data merged on a device that is always-on and always-connected and that can easily be extended with new software greatly improves user convenience. On the other hand, it also poses new questions with regard to privacy and security. Apps may misuse the data stored on the phone or obtained from the sensors to infringe upon the user's privacy. In fact, companies already now use location data and app usage statistics to build user profiles for the purpose of targeted advertisement. The user is oftentimes unaware of these data leaks originating from his phone and has little means for analyzing the actual behavior of a given app with regard to privacy.

Static data flow analysis has been proposed as a means for automatically enumerating the data flows inside a program. Still, either do not support Android's platform-specific semantics or fall short on precision, recall, or scalability. In this thesis, we therefore propose techniques for efficiently and precisely performing static data flow analysis on real-world binary-only Android apps with large code sizes. We present the FlowDroid tool and show that it can detect data leaks in popular apps such as Facebook, Paypal, and LinkedIn. The FlowDroid reports improve the user's digital sovereignty by allowing his to asses the behavior of the app before installing it on his device and thereby entrusting it with his personal data. We allow the user to verify which of his data leaves the device and how. On the DroidBench micro-benchmark suite, we show that FlowDroid achieves a precision of more than 87\% and a recall of over 84\%, thereby outperforming state-of-the-art tools from academia and industry. Additionally, FlowDroid has already been used as a building-block for many other works in the field.},
  copyright = {lediglich die vom Gesetz vorgesehenen Nutzungsrechte gemäß UrhG},
  file      = {Full Text PDF:https\://tuprints.ulb.tu-darmstadt.de/5937/7/Thesis.pdf:application/pdf},
  language  = {en},
  url       = {https://tuprints.ulb.tu-darmstadt.de/5937/},
  urldate   = {2021-01-28},
}

@InProceedings{Lerch2015,
  author    = {Johannes Lerch and Ben Hermann},
  booktitle = {Proceedings of the 4th {ACM} {SIGPLAN} International Workshop on State Of the Art in Program Analysis},
  title     = {Design your analysis: a case study on implementation reusability of data-flow functions},
  year      = {2015},
  month     = {jun},
  publisher = {{ACM}},
  doi       = {10.1145/2771284.2771289},
}

@InProceedings{Reps1995,
  author    = {Thomas Reps and Susan Horwitz and Mooly Sagiv},
  booktitle = {Proceedings of the 22nd {ACM} {SIGPLAN}-{SIGACT} symposium on Principles of programming languages - {POPL} {\textquotesingle}95},
  title     = {Precise interprocedural dataflow analysis via graph reachability},
  year      = {1995},
  publisher = {{ACM} Press},
  doi       = {10.1145/199448.199462},
}

@InCollection{Naeem2010,
  author    = {Nomair A. Naeem and Ond{\v{r}}ej Lhot{\'{a}}k and Jonathan Rodriguez},
  booktitle = {Lecture Notes in Computer Science},
  publisher = {Springer Berlin Heidelberg},
  title     = {Practical Extensions to the {IFDS} Algorithm},
  year      = {2010},
  pages     = {124--144},
  doi       = {10.1007/978-3-642-11970-5_8},
}

@Article{Arzt2014,
  author    = {Steven Arzt and Siegfried Rasthofer and Christian Fritz and Eric Bodden and Alexandre Bartel and Jacques Klein and Yves Le Traon and Damien Octeau and Patrick McDaniel},
  journal   = {{ACM} {SIGPLAN} Notices},
  title     = {{FlowDroid}},
  year      = {2014},
  month     = {jun},
  number    = {6},
  pages     = {259--269},
  volume    = {49},
  doi       = {10.1145/2666356.2594299},
  publisher = {Association for Computing Machinery ({ACM})},
}

@Article{Valleerai2004,
  author     = {Vallee-rai, Raja and Hendren, Laurie},
  title      = {Jimple: {Simplifying} {Java} {Bytecode} for {Analyses} and {Transformations}},
  year       = {2004},
  month      = jan,
  abstract   = {In this paper we present Jimple, a 3-address intermediaterepresentation that has been designed tosimplify analysis and transformation of Java bytecode.We motivate the need for a new intermediaterepresentation by illustrating several difficultieswith optimizing the stack-based Java bytecode directly.In general, these difficulties are due to thefact that bytecode instructions affect an expressionstack, and thus have implicit uses and definitions ofstack locations. We propose Jimple as an ...},
  file       = {ResearchGate Link:https\://www.researchgate.net/publication/243776080_Jimple_Simplifying_Java_Bytecode_for_Analyses_and_Transformations:},
  shorttitle = {Jimple},
}

@InProceedings{Bodden2012,
  author    = {Eric Bodden},
  booktitle = {Proceedings of the {ACM} {SIGPLAN} International Workshop on State of the Art in Java Program analysis - {SOAP} {\textquotesingle}12},
  title     = {Inter-procedural data-flow analysis with {IFDS}/{IDE} and Soot},
  year      = {2012},
  publisher = {{ACM} Press},
  doi       = {10.1145/2259051.2259052},
}

@InProceedings{Yan2017,
  author    = {Yan, X. and Ma, H. and Wang, Q.},
  booktitle = {2017 {IEEE} 9th {International} {Conference} on {Communication} {Software} and {Networks} ({ICCSN})},
  title     = {A static backward taint data analysis method for detecting web application vulnerabilities},
  year      = {2017},
  month     = may,
  note      = {ISSN: 2472-8489},
  pages     = {1138--1141},
  abstract  = {This paper addresses detecting taint-style vulnerabilities in PHP code. It extends classical taint-style model with an element called “cleans”, which is used to specify sanitation routines. Based on the new model, a static backward taint data analysis method is proposed to detecting taint-style vulnerabilities. This method includes four key steps, first of which is collecting sinks and constructing contexts, the second is backward tracing variables during a basic block, the third is tracing variables between blocks, and the last is tracing variables crossing function call. A tool called POSE implements this method and testing results show that the method is valid for detecting taint-style web application vulnerabilities.},
  doi       = {10.1109/ICCSN.2017.8230288},
  file      = {IEEE Xplore Full Text PDF:https\://ieeexplore.ieee.org/stampPDF/getPDF.jsp?tp=&arnumber=8230288&ref=aHR0cHM6Ly9pZWVleHBsb3JlLmllZWUub3JnL2RvY3VtZW50LzgyMzAyODg=:application/pdf},
  issn      = {2472-8489},
  keywords  = {data analysis, Internet, program diagnostics, programming, security of data, software tools, static backward taint data analysis method, taint-style web application vulnerabilities, classical taint-style model, POSE implements, PHP code, Web application vulnerabilities detection, taint-style vulnerabilities detection, Data analysis, Data models, Tools, Algorithm design and analysis, Reactive power, taint data analysis, PHP, web application, vulnerabilities},
}

@Book{Muchnick1997,
  author    = {Steven S. Muchnick},
  publisher = {Morgan Kaufmann},
  title     = {Advanced Compiler Design and Implementation},
  year      = {1997},
  isbn      = {1-55860-320-4},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/books/mk/Muchnick1997.bib},
  timestamp = {Mon, 05 Jan 2004 14:58:03 +0100},
}

@Book{Khedker2009,
  author     = {Khedker, Uday and Sanyal, Amitabha and Sathe, Bhaurao},
  title      = {Data {Flow} {Analysis}: {Theory} and {Practice}},
  year       = {2009},
  isbn       = {9780849332517},
  month      = jan,
  abstract   = {This work provides an in-depth treatment of data flow analysis technique. Apart from including interprocedural data flow analysis, this book is the first to extend detailed coverage of analysis beyond bit vectors. Supplemented by numerous examples, it equips readers with a combination of mutually supportive theory and practice, presenting mathematical foundations and including study of data flow analysis implementation through use of the GNU Compiler Collection (GCC). Readers can experiment with the analyses described in the book by accessing the authors web page, where they will find the source code of gdfa (generic data flow analyzer).},
  doi        = {10.1201/9780849332517},
  file       = {ResearchGate Link:https\://www.researchgate.net/publication/262493821_Data_Flow_Analysis_Theory_and_Practice:},
  journal    = {Data Flow Analysis: Theory and Practice},
  shorttitle = {Data {Flow} {Analysis}},
}

@InProceedings{Jones1979,
  author   = {Jones, Neil and Muchnick, Steven},
  title    = {Flow {Analysis} and {Optimization} of {Lisp}-{Like} {Structures}.},
  year     = {1979},
  month    = jan,
  pages    = {244--256},
  abstract = {In [12] the authors introduced the concept of binding time optimization and presented a series of data flow analytic methods for determining some of the binding time characteristics of programs. In this paper we extend that work by providing methods for determining the class of shapes which an unbounded data object may assume during execution of a LISP-like program, and describe a number of uses to which that information may be put to improve storage allocation in compilers and interpreters for advanced programming languages.We are concerned chiefly with finding, for each program point and variable a finite description of a set of graphs which includes all the shapes of values the variable could assume at that point during the execution of a program. If this set is small or regular in structure, this information can be used to optimize the program's execution, mainly by use of more efficient storage allocation schemes.In the first part we show how to construct from a program without selective updating a tree grammar whose nonterminals generate the desired sets of graphs; in this case they will all be trees. The tree grammars are of a more general form than is usually studied [8, 19], so we show that they may be converted to the usual form. The resulting tree grammar could naturally be viewed as a recursive type definition [11] of the values the variables may assume. Further, standard algorithms may be employed to test for infiniteness, emptiness or linearity of the tree structure.In the second part selective updating is allowed, so an alternate semantics is introduced which more closely resembles traditional LISP implementations, and which is equivalent to the tree model for programs without selective updating. In this model data objects are directed graphs. We devise a finite approximation method which provides enough information to detect cell sharing and cyclic structures whenever they can possibly occur. This information can be used to recognize when the use of garbage collection or of reference counts may be avoided.The work reported in the second part of this paper extends that of Schwartz [17] and Cousot and Cousot [7]. They have developed methods for determining whether the values of two or more variables share cells, while we provide information on the detailed structure of what is shared. The ability to detect cycles is also new. It also extends the work of Kaplan [13], who distinguishes only binary relations among the variables of a program, does not handle cycles, and does not distinguish selectors (so that his analysis applies to nodes representing sets rather than ordered tuples).},
  doi      = {10.1145/567752.567776},
  file     = {Full Text PDF:https\://www.researchgate.net/profile/Neil-Jones-12/publication/220997426_Flow_Analysis_and_Optimization_of_Lisp-Like_Structures/links/00b4951922ad3ee2bc000000/Flow-Analysis-and-Optimization-of-Lisp-Like-Structures.pdf:application/pdf;ResearchGate Link:https\://www.researchgate.net/publication/220997426_Flow_Analysis_and_Optimization_of_Lisp-Like_Structures:},
}

@InProceedings{Bravenboer2009,
  author   = {Bravenboer, M. and Smaragdakis, Yannis},
  title    = {Strictly {Declarative} {Specification} of {Sophisticated} {Points}-to {Analyses}},
  year     = {2009},
  month    = oct,
  pages    = {243--262},
  volume   = {44},
  abstract = {We present the DOOP framework for points-to analysis of Java programs. DOOP builds on the idea of specifying pointer analysis algorithms declaratively, using Datalog: a logic-based language for defining (recursive) relations. We carry the declarative approach further than past work by describing the full end-to-end analysis in Datalog and optimizing aggressively using a novel technique specifically targeting highly recursive Datalog programs.
As a result, DOOP achieves several benefits, including full order-of-magnitude improvements in runtime. We compare DOOP with Lhotak and Hendren's PADDLE, which defines the state of the art for context-sensitive analyses. For the exact same logical points-to definitions (and, consequently, identical precision) DOOP is more than 15x faster than PADDLE for a 1-call-site sensitive analysis of the DaCapo benchmarks, with lower but still substantial speedups for other important analyses. Additionally, DOOP scales to very precise analyses that are impossible with PADDLE and Whaley et al.'s bddbddb, directly addressing open problems in past literature. Finally, our implementation is modular and can be easily configured to analyses with a wide range of characteristics, largely due to its declarativeness.},
  doi      = {10.1145/1640089.1640108},
  file     = {Full Text PDF:https\://www.researchgate.net/profile/M-Bravenboer/publication/221321022_Strictly_Declarative_Specification_of_Sophisticated_Points-to_Analyses/links/552413cd0cf2caf11bfcbf1e/Strictly-Declarative-Specification-of-Sophisticated-Points-to-Analyses.pdf:application/pdf;ResearchGate Link:https\://www.researchgate.net/publication/221321022_Strictly_Declarative_Specification_of_Sophisticated_Points-to_Analyses:},
}

@InProceedings{Arzt2021,
  author    = {Arzt, Steven},
  booktitle = {ICSE 2021 Technical Track},
  title     = {{Sustainable Solving}: Reducing The Memory Footprint of IFDS-Based Data Flow Analyses Using Intelligent Garbage Collection},
  year      = {2021},
}

@InProceedings{Spaeth2016,
  author     = {Spaeth, J. and Do, L. and Ali, Karim and Bodden, E.},
  booktitle  = {{ECOOP}},
  title      = {Boomerang: {Demand}-{Driven} {Flow}- and {Context}-{Sensitive} {Pointer} {Analysis} for {Java}},
  year       = {2016},
  abstract   = {Many current program analyses require highly precise pointer 
information about small, tar- geted parts of a given program. This 
motivates the need for demand-driven pointer analyses that compute 
information only where required. Pointer analyses generally compute 
points-to sets of program variables or answer boolean alias 
queries. However, many client analyses require richer pointer 
information. For example, taint and typestate analyses often need to 
know the set of all aliases of a given variable under a certain 
calling context. With most current pointer analyses, clients must 
compute such information through repeated points-to or alias queries, increasing complexity and computation time for them. 
 
This paper presents Boomerang, a demand-driven, flow-, field-, and 
context-sensitive pointer analysis for Java programs. Boomerang 
computes rich results that include both the possible allocation sites of a given pointer (points-to information) and all pointers that can point to those allocation sites (alias information). For increased precision and scalability, clients can query Boomerang with respect to particular calling contexts of interest. 
 
Our experiments show that Boomerang is more precise than existing 
demand-driven pointer analyses. Additionally, using Boomerang, the 
taint analysis FlowDroid issues up to 29.4x fewer pointer queries 
compared to using other pointer analyses that return simpler pointer 
infor- mation. Furthermore, the search space of Boomerang can be 
significantly reduced by requesting calling contexts from the client 
analysis.},
  doi        = {10.4230/LIPIcs.ECOOP.2016.22},
  file       = {Semantic Scholar Link:https\://www.semanticscholar.org/paper/Boomerang%3A-Demand-Driven-Flow-and-Context-Sensitive-Spaeth-Do/12cf1936871e27e985d6a8395c0b62d220e62b21:text/html},
  shorttitle = {Boomerang},
}

@InProceedings{Winter2013,
  author    = {Winter, Kirsten and Zhang, Chenyi and Hayes, Ian J. and Keynes, Nathan and Cifuentes, Cristina and Li, Lian},
  booktitle = {Formal {Methods} and {Software} {Engineering}},
  title     = {Path-{Sensitive} {Data} {Flow} {Analysis} {Simplified}},
  year      = {2013},
  address   = {Berlin, Heidelberg},
  editor    = {Groves, Lindsay and Sun, Jing},
  pages     = {415--430},
  publisher = {Springer},
  series    = {Lecture {Notes} in {Computer} {Science}},
  abstract  = {Path-sensitive data flow analysis pairs classical data flow analysis with an analysis of feasibility of paths to improve precision. In this paper we propose a framework for path-sensitive backward data flow analysis that is enhanced with an abstraction of the predicate domain. The abstraction is based on a three-valued logic. It follows the strategy that path predicates are simplified if possible (without calling an external predicate solver) and every predicate that could not be reduced to a simple predicate is abstracted to the unknown value, for which the feasibility is undecided. The implementation of the framework scales well and delivers promising results.},
  doi       = {10.1007/978-3-642-41202-8_27},
  file      = {Springer Full Text PDF:https\://link.springer.com/content/pdf/10.1007%252F978-3-642-41202-8_27.pdf:application/pdf},
  isbn      = {9783642412028},
  keywords  = {Information Order , Disjunctive Normal Form , Feasible Path , Abstract Domain , Complex Predicate },
  language  = {en},
}

@Article{Arshad2014,
  author    = {Arshad, Syed and Kumar, Ashwin},
  journal   = {IJCA Proceedings on International Conference on Information and Communication Technologies},
  title     = {Android {Application} {Analysis} using {Reverse} {Engineering} {Techniques} and {Taint}-{Aware} {Slicing}},
  year      = {2014},
  month     = aug,
  number    = {4},
  pages     = {5--8},
  volume    = {ICICT},
  abstract  = {IJCA is a computer science and electronics journal related with Theoretical Informatics, Quantum Computing, Software Testing, Computer Vision, Digital Systems, Pervasive Computing, Computational Topology etc.},
  file      = {Full Text PDF:http\://research.ijcaonline.org/icict/number4/icict1436.pdf:application/pdf},
  language  = {en-gb},
  publisher = {Foundation of Computer Science (FCS)},
  url       = {https://www.ijcaonline.org/proceedings/icict/number4/17984-1436},
  urldate   = {2021-04-14},
}

@Article{Tripp2009,
  author    = {Omer Tripp and Marco Pistoia and Stephen J. Fink and Manu Sridharan and Omri Weisman},
  journal   = {{ACM} {SIGPLAN} Notices},
  title     = {{TAJ}},
  year      = {2009},
  month     = {may},
  number    = {6},
  pages     = {87--97},
  volume    = {44},
  doi       = {10.1145/1543135.1542486},
  publisher = {Association for Computing Machinery ({ACM})},
}

@InProceedings{Livshits2005,
  author    = {Livshits, B. and Lam, M.},
  booktitle = {{USENIX} {Security} {Symposium}},
  title     = {Finding {Security} {Vulnerabilities} in {Java} {Applications} with {Static} {Analysis}},
  year      = {2005},
  abstract  = {This paper proposes a static analysis technique for detecting many recently discovered application vulnerabilities such as SQL injections, cross-site scripting, and HTTP splitting attacks. These vulnerabilities stem from unchecked input, which is widely recognized as the most common source of security vulnerabilities in Web applications. We propose a static analysis approach based on a scalable and precise points-to analysis. In our system, user-provided specifications of vulnerabilities are automatically translated into static analyzers. Our approach finds all vulnerabilities matching a specification in the statically analyzed code. Results of our static analysis are presented to the user for assessment in an auditing interface integrated within Eclipse, a popular Java development environment. 
 
Our static analysis found 29 security vulnerabilities in nine large, popular open-source applications, with two of the vulnerabilities residing in widely-used Java libraries. In fact, all but one application in our benchmark suite had at least one vulnerability. Context sensitivity, combined with improved object naming, proved instrumental in keeping the number of false positives low. Our approach yielded very few false positives in our experiments: in fact, only one of our benchmarks suffered from false alarms.},
  file      = {Semantic Scholar Link:https\://www.semanticscholar.org/paper/Finding-Security-Vulnerabilities-in-Java-with-Livshits-Lam/3b6c4ca09a1a48af7684ede1398b51b5be0f7581:text/html},
}

@InProceedings{Krueger2017,
  author     = {Krüger, S. and Nadi, S. and Reif, M. and Ali, K. and Mezini, M. and Bodden, E. and Göpfert, F. and Günther, F. and Weinert, C. and Demmler, D. and Kamath, R.},
  booktitle  = {2017 32nd {IEEE}/{ACM} {International} {Conference} on {Automated} {Software} {Engineering} ({ASE})},
  title      = {{CogniCrypt}: {Supporting} developers in using cryptography},
  year       = {2017},
  month      = oct,
  pages      = {931--936},
  abstract   = {Previous research suggests that developers often struggle using low-level cryptographic APIs and, as a result, produce insecure code. When asked, developers desire, among other things, more tool support to help them use such APIs. In this paper, we present CogniCrypt, a tool that supports developers with the use of cryptographic APIs. CogniCrypt assists the developer in two ways. First, for a number of common cryptographic tasks, CogniCrypt generates code that implements the respective task in a secure manner. Currently, CogniCrypt supports tasks such as data encryption, communication over secure channels, and long-term archiving. Second, CogniCrypt continuously runs static analyses in the background to ensure a secure integration of the generated code into the developer's workspace. This video demo showcases the main features of CogniCrypt: youtube.com/watch?v=JUq5mRHfAWY.},
  doi        = {10.1109/ASE.2017.8115707},
  file       = {IEEE Xplore Full Text PDF:https\://ieeexplore.ieee.org/stampPDF/getPDF.jsp?tp=&arnumber=8115707&ref=aHR0cHM6Ly9pZWVleHBsb3JlLmllZWUub3JnL2RvY3VtZW50LzgxMTU3MDc=:application/pdf},
  keywords   = {Tools, Ciphers, Encryption, Java, Cryptography, Code Generation, Variability Modeling, Code Analysis},
  shorttitle = {{CogniCrypt}},
}

@InProceedings{King2008,
  author     = {King, Dave and Hicks, Boniface and Hicks, Michael and Jaeger, Trent},
  booktitle  = {Information {Systems} {Security}},
  title      = {Implicit {Flows}: {Can}’t {Live} with ‘{Em}, {Can}’t {Live} without ‘{Em}},
  year       = {2008},
  address    = {Berlin, Heidelberg},
  editor     = {Sekar, R. and Pujari, Arun K.},
  pages      = {56--70},
  publisher  = {Springer},
  series     = {Lecture {Notes} in {Computer} {Science}},
  abstract   = {Verifying that programs trusted to enforce security actually do so is a practical concern for programmers and administrators. However, there is a disconnect between the kinds of tools that have been successfully applied to real software systems (such as taint mode in Perl and Ruby), and information-flow compilers that enforce a variant of the stronger security property of noninterference. Tools that have been successfully used to find security violations have focused on explicit flows of information, where high-security information is directly leaked to output. Analysis tools that enforce noninterference also prevent implicit flows of information, where high-security information can be inferred from a program’s flow of control. However, these tools have seen little use in practice, despite the stronger guarantees that they provide.To better understand why, this paper experimentally investigates the explicit and implicit flows identified by the standard algorithm for establishing noninterference. When applied to implementations of authentication and cryptographic functions, the standard algorithm discovers many real implicit flows of information, but also reports an extremely high number of false alarms, most of which are due to conservative handling of unchecked exceptions (e.g., null pointer exceptions). After a careful analysis of all sources of true and false alarms, due to both implicit and explicit flows, the paper concludes with some ideas to improve the false alarm rate, toward making stronger security analysis more practical.},
  doi        = {10.1007/978-3-540-89862-7_4},
  file       = {Springer Full Text PDF:https\://link.springer.com/content/pdf/10.1007%2F978-3-540-89862-7_4.pdf:application/pdf},
  isbn       = {9783540898627},
  keywords   = {False Alarm , False Alarm Rate , Null Pointer , Secret Data , Authentication Method },
  language   = {en},
  shorttitle = {Implicit {Flows}},
}

@InProceedings{Scholz2016,
  author   = {Scholz, Bernhard and Jordan, Herbert and Subotic, Pavle and Westmann, Till},
  title    = {On {Fast} {Large}-{Scale} {Program} {Analysis} in {Datalog}},
  year     = {2016},
  month    = mar,
  pages    = {196--206},
  abstract = {Designing and crafting a static program analysis is challenging due to the complexity of the task at hand. Among the challenges are modelling the semantics of the input language, finding suitable abstractions for the analysis, and handwriting efficient code for the analysis in a traditional imperative language such as C++. Hence, the development of static program analysis tools is costly in terms of development time and resources for real world languages. To overcome, or at least alleviate the costs of developing a static program analysis, Datalog has been proposed as a domain specific language (DSL). With Datalog, a designer expresses a static program analysis in the form of a logical specification. While a domain specific language approach aids in the ease of development of program analyses, it is commonly accepted that such an approach has worse runtime performance than handcrafted static analysis tools. In this work, we introduce a new program synthesis methodology for Datalog specifications to produce highly efficient monolithic C++ analyzers. The synthesis technique requires the re-interpretation of the semi-naive evaluation as a scaffolding for translation using partial evaluation. To achieve high-performance, we employ staged-compilation techniques and specialize the underlying relational data structures for a given Datalog specification. Experimentation on benchmarks for large-scale program analysis validates the superior performance of our approach over available Datalog tools and demonstrates our competitiveness with state-of-the-art handcrafted tools.},
  doi      = {10.1145/2892208.2892226},
  file     = {ResearchGate Link:https\://www.researchgate.net/publication/311488907_On_Fast_Large-Scale_Program_Analysis_in_Datalog:},
}

@InProceedings{Gibler2012,
  author     = {Gibler, Clint and Crussell, Jonathan and Erickson, Jeremy and Chen, Hao},
  booktitle  = {Trust and {Trustworthy} {Computing}},
  title      = {{AndroidLeaks}: {Automatically} {Detecting} {Potential} {Privacy} {Leaks} in {Android} {Applications} on a {Large} {Scale}},
  year       = {2012},
  address    = {Berlin, Heidelberg},
  editor     = {Katzenbeisser, Stefan and Weippl, Edgar and Camp, L. Jean and Volkamer, Melanie and Reiter, Mike and Zhang, Xinwen},
  pages      = {291--307},
  publisher  = {Springer},
  series     = {Lecture {Notes} in {Computer} {Science}},
  abstract   = {As mobile devices become more widespread and powerful, they store more sensitive data, which includes not only users’ personal information but also the data collected via sensors throughout the day. When mobile applications have access to this growing amount of sensitive information, they may leak it carelessly or maliciously.Google’s Android operating system provides a permissions-based security model that restricts an application’s access to the user’s private data. Each application statically declares the sensitive data and functionality that it requires in a manifest, which is presented to the user upon installation. However, it is not clear to the user how sensitive data is used once the application is installed. To combat this problem, we present AndroidLeaks, a static analysis framework for automatically finding potential leaks of sensitive information in Android applications on a massive scale. AndroidLeaks drastically reduces the number of applications and the number of traces that a security auditor has to verify manually.We evaluate the efficacy of AndroidLeaks on 24,350 Android applications from several Android markets. AndroidLeaks found 57,299 potential privacy leaks in 7,414 Android applications, out of which we have manually verified that 2,342 applications leak private data including phone information, GPS location, WiFi data, and audio recorded with the microphone. AndroidLeaks examined these applications in 30 hours, which indicates that it is capable of scaling to the increasingly large set of available applications.},
  doi        = {10.1007/978-3-642-30921-2_17},
  file       = {Springer Full Text PDF:https\://link.springer.com/content/pdf/10.1007%2F978-3-642-30921-2_17.pdf:application/pdf},
  isbn       = {9783642309212},
  keywords   = {Private Data , Android Application , Native Code , Privacy Leak , Java Source Code },
  language   = {en},
  shorttitle = {{AndroidLeaks}},
}

@InProceedings{Zhao2012,
  author     = {Zhao, Z. and Osono, F. C. Colon},
  booktitle  = {2012 7th {International} {Conference} on {Malicious} and {Unwanted} {Software}},
  title      = {“{TrustDroid}™”: {Preventing} the use of {SmartPhones} for information leaking in corporate networks through the used of static analysis taint tracking},
  year       = {2012},
  month      = oct,
  pages      = {135--143},
  abstract   = {Over the last 12 years three important dates have marked the beginning of a major paradigm shift in computing and the security models applied to protect an emerging computing environment - March 1999, January 9th, 2007, and July 2007. These dates roughly correspond to the birth of SalesForce.com, the most successful Software as a Service (SaS) provider to date, Steve Jobs introduction of the Iphone,, and the discovery of the Zeus Botnet. These innovations have been instrumental in enabling a paradigm shift in computing, away from a corporate network centric model with Windows end-point devices to what we called in this manuscript the Circa 2020 Computing Model. In the circa 2020 Computing model applications and data reside in the Cloud, the concept of an extended Trust Domain (network) disappears - there is no corporate network, and finally the end-point device is a SmartPhone owned and operated by employees - Bring Your Own Device (BYOD). In such an environment, the end-point device is not “Trusted”, and there is a high likelihood that the BYOD can be used as a channel to leak sensitive data. In this manuscript, we present a new mechanism to prevent such a situation. We called this mechanism “TrustDroid™”. TrustDroid™ is a static analyzer based on taint tracking that can be used to prevent leakage of sensitive information by an un-trusted Android SmartPhone.},
  doi        = {10.1109/MALWARE.2012.6461017},
  file       = {IEEE Xplore Full Text PDF:https\://ieeexplore.ieee.org/stampPDF/getPDF.jsp?tp=&arnumber=6461017&ref=aHR0cHM6Ly9pZWVleHBsb3JlLmllZWUub3JnL2Fic3RyYWN0L2RvY3VtZW50LzY0NjEwMTc=:application/pdf},
  keywords   = {Sockets, Telephony, Abstracts, Libraries, Software},
  shorttitle = {“{TrustDroid}™”},
}

@InProceedings{Yang2012,
  author     = {Yang, Z. and Yang, M.},
  booktitle  = {2012 {Third} {World} {Congress} on {Software} {Engineering}},
  title      = {{LeakMiner}: {Detect} {Information} {Leakage} on {Android} with {Static} {Taint} {Analysis}},
  year       = {2012},
  month      = nov,
  pages      = {101--104},
  abstract   = {With the growing popularity of Android platform, Android application market becomes a major distribution center where Android users download apps. Unlike most of the PC apps, Android apps manipulates personal information such as contract and SMS messages, and leakage of such information may cause great loss to the Android users. Thus, detecting information leakage on Android is in urgent need. However, till now, there is still no complete vetting process applied to Android markets. State-of-the-art approaches for detecting Android information leakage apply dynamic analysis on user site, thus they introduce large runtime overhead to the Android apps. This paper proposes a new approach called Leak Miner, which detects leakage of sensitive information on Android with static taint analysis. Unlike dynamic approaches, Leak Miner analyzes Android apps on market site. Thus, it does not introduce runtime overhead to normal execution of target apps. Besides, Leak Miner can detect information leakage before apps are distributed to users, so malicious apps can be removed from market before users download them. Our evaluation result shows that Leak Miner can detect 145 true information leakages inside a 1750 app set.},
  doi        = {10.1109/WCSE.2012.26},
  file       = {IEEE Xplore Full Text PDF:https\://ieeexplore.ieee.org/stampPDF/getPDF.jsp?tp=&arnumber=6394931&ref=aHR0cHM6Ly9pZWVleHBsb3JlLmllZWUub3JnL2RvY3VtZW50LzYzOTQ5MzE=:application/pdf},
  keywords   = {Smart phones, Androids, Humanoid robots, Java, Context, Security, Runtime, Information security, Mobile computing},
  shorttitle = {{LeakMiner}},
}

@InProceedings{Mann2012,
  author    = {Mann, Christopher and Starostin, A.},
  booktitle = {{SAC} '12},
  title     = {A framework for static detection of privacy leaks in android applications},
  year      = {2012},
  abstract  = {We report on applying techniques for static information flow analysis to identify privacy leaks in Android applications. We have crafted a framework which checks with the help of a security type system whether the Dalvik bytecode implementation of an Android app conforms to a given privacy policy. We have carefully analyzed the Android API for possible sources and sinks of private data and identified exemplary privacy policies based on this. We demonstrate the applicability of our framework on two case studies showing detection of privacy leaks.},
  doi       = {10.1145/2245276.2232009},
  file      = {Semantic Scholar Link:https\://www.semanticscholar.org/paper/A-framework-for-static-detection-of-privacy-leaks-Mann-Starostin/d8761cdf360eb686bd7d182ef4167f54ef192085:text/html},
}

@Article{Binns2018,
  author   = {Binns, Reuben and Lyngs, Ulrik and Kleek, M. V. and Zhao, Jun and Libert, Timothy and Shadbolt, N.},
  journal  = {WebSci},
  title    = {Third {Party} {Tracking} in the {Mobile} {Ecosystem}},
  year     = {2018},
  abstract = {Third party tracking allows companies to identify users and track their behaviour across multiple digital services. This paper presents an empirical study of the prevalence of third-party trackers on 959,000 apps from the US and UK Google Play stores. We find that most apps contain third party tracking, and the distribution of trackers is long-tailed with several highly dominant trackers accounting for a large portion of the coverage. The extent of tracking also differs between categories of apps; in particular, news apps and apps targeted at children appear to be amongst the worst in terms of the number of third party trackers associated with them. Third party tracking is also revealed to be a highly trans-national phenomenon, with many trackers operating in jurisdictions outside the EU. Based on these findings, we draw out some significant legal compliance challenges facing the tracking industry.},
  doi      = {10.1145/3201064.3201089},
  file     = {Semantic Scholar Link:https\://www.semanticscholar.org/paper/Third-Party-Tracking-in-the-Mobile-Ecosystem-Binns-Lyngs/40cf9ef2f6db11dbb1361825f65a7cc21eddf16e:text/html},
}

@InProceedings{Enck2011,
  author    = {Enck, William and Octeau, Damien and McDaniel, P. and Chaudhuri, Swarat},
  booktitle = {{USENIX} {Security} {Symposium}},
  title     = {A {Study} of {Android} {Application} {Security}},
  year      = {2011},
  abstract  = {The fluidity of application markets complicate smartphone security. Although recent efforts have shed light on particular security issues, there remains little insight into broader security characteristics of smartphone applications. This paper seeks to better understand smartphone application security by studying 1,100 popular free Android applications. We introduce the ded decompiler, which recovers Android application source code directly from its installation image. We design and execute a horizontal study of smartphone applications based on static analysis of 21 million lines of recovered code. Our analysis uncovered pervasive use/misuse of personal/ phone identifiers, and deep penetration of advertising and analytics networks. However, we did not find evidence of malware or exploitable vulnerabilities in the studied applications. We conclude by considering the implications of these preliminary findings and offer directions for future analysis.},
  file      = {Semantic Scholar Link:https\://www.semanticscholar.org/paper/A-Study-of-Android-Application-Security-Enck-Octeau/a25cec5c05ffcbda885044d0c67bfdc698adcccd:text/html},
}

@Article{Kotzias2021,
  author     = {Kotzias, Platon and Caballero, Juan and Bilge, Leyla},
  journal    = {42nd IEEE Symposium onSecurity and Privacy},
  title      = {How {Did} {That} {Get} {In} {My} {Phone}? {Unwanted} {App} {Distribution} on {Android} {Devices}},
  year       = {2021},
  abstract   = {Android is the most popular operating system with billions of active devices. Unfortunately, its popularity and openness makes it attractive for unwanted apps, i.e., malware and potentially unwanted programs (PUP). In Android, app installations typically happen via the official and alternative markets, but also via other smaller and less understood alternative distribution vectors such as Web downloads, pay-per-install (PPI) services, backup restoration, bloatware, and IM tools. This work performs a thorough investigation on unwanted app distribution by quantifying and comparing distribution through different vectors. At the core of our measurements are reputation logs of a large security vendor, which include 7.9M apps observed in 12M devices between June and September 2019. As a first step, we measure that between 10\% and 24\% of users devices encounter at least one unwanted app, and compare the prevalence of malware and PUP. An analysis of the who-installs-who relationships between installers and child apps reveals that the Play market is the main app distribution vector, responsible for 87\% of all installs and 67\% of unwanted app installs, but it also has the best defenses against unwanted apps. Alternative markets distribute instead 5.7\% of all apps, but over 10\% of unwanted apps. Bloatware is also a significant unwanted app distribution vector with 6\% of those installs. And, backup restoration is an unintentional distribution vector that may even allow unwanted apps to survive users' phone replacement. We estimate unwanted app distribution via PPI to be smaller than on Windows. Finally, we observe that Web downloads are rare, but provide a riskier proposition even compared to alternative markets.},
  file       = {Semantic Scholar Link:https\://www.semanticscholar.org/paper/How-Did-That-Get-In-My-Phone-Unwanted-App-on-Kotzias-Caballero/b2a2e799beb396b1d42cc20174e5f27a7259fb06:text/html;Full Text PDF:https\://arxiv.org/pdf/2010.10088.pdf:application/pdf},
  shorttitle = {How {Did} {That} {Get} {In} {My} {Phone}?},
}

@InProceedings{Rahman2016,
  author     = {Rahman, Mahmudur and Rahman, Mizanur and Carbunar, Bogdan and Chau, Duen Horng},
  title      = {{FairPlay}: {Fraud} and {Malware} {Detection} in {Google} {Play}},
  year       = {2016},
  month      = jun,
  abstract   = {Fraudulent behaviors in Google's Android app market fuel search rank abuse and malware proliferation. We present FairPlay, a novel system that uncovers both malware and search rank fraud apps, by picking out trails that fraudsters leave behind. To identify suspicious apps, FairPlay's PCF algorithm correlates review activities and uniquely combines detected review relations with linguistic and behavioral signals gleaned from longitudinal Google Play app data. We contribute a new longitudinal app dataset to the community, which consists of over 87K apps, 2.9M reviews, and 2.4M reviewers , collected over half a year. FairPlay achieves over 95\% accuracy in classifying gold standard datasets of malware, fraudulent and legitimate apps. We show that 75\% of the identified malware apps engage in search rank fraud. FairPlay discovers hundreds of fraudulent apps that currently evade Google Bouncer's detection technology, and reveals a new type of attack campaign, where users are harassed into writing positive reviews, and install and review other apps.},
  doi        = {10.1137/1.9781611974348.12},
  file       = {Full Text PDF:https\://www.researchgate.net/profile/Mizanur-Rahman-3/publication/289503269_FairPlay_Fraud_and_Malware_Detection_in_Google_Play/links/57ac0ba908ae42ba52af38d4/FairPlay-Fraud-and-Malware-Detection-in-Google-Play.pdf:application/pdf;ResearchGate Link:https\://www.researchgate.net/publication/289503269_FairPlay_Fraud_and_Malware_Detection_in_Google_Play:},
  shorttitle = {{FairPlay}},
}

@Article{Backes2016,
  author   = {Backes, M. and Bugiel, S. and Derr, Erik},
  journal  = {CCS},
  title    = {Reliable {Third}-{Party} {Library} {Detection} in {Android} and its {Security} {Applications}},
  year     = {2016},
  abstract = {Third-party libraries on Android have been shown to be security and privacy hazards by adding security vulnerabilities to their host apps or by misusing inherited access rights. Correctly attributing improper app behavior either to app or library developer code or isolating library code from their host apps would be highly desirable to mitigate these problems, but is impeded by the absence of a third-party library detection that is effective and reliable in spite of obfuscated code. This paper proposes a library detection technique that is resilient against common code obfuscations and that is capable of pinpointing the exact library version used in apps. Libraries are detected with profiles from a comprehensive library database that we generated from the original library SDKs. We apply our technique to the top apps on Google Play and their complete histories to conduct a longitudinal study of library usage and evolution in apps. Our results particularly show that app developers only slowly adapt new library versions, exposing their end-users to large windows of vulnerability. For instance, we discovered that two long-known security vulnerabilities in popular libs are still present in the current top apps. Moreover, we find that misuse of cryptographic APIs in advertising libs, which increases the host apps' attack surface, affects 296 top apps with a cumulative install base of 3.7bn devices according to Play. To the best of our knowledge, our work is first to quantify the security impact of third-party libs on the Android ecosystem.},
  doi      = {10.1145/2976749.2978333},
  file     = {Semantic Scholar Link:https\://www.semanticscholar.org/paper/Reliable-Third-Party-Library-Detection-in-Android-Backes-Bugiel/ea4f8cd1495903cc262d255db8bbd697180e194b:text/html},
}

@Misc{Statista2021,
  title    = {Mobile {OS} market share 2021},
  year     = {2021},
  abstract = {The Android operating system (OS) has the highest market share worldwide on mobile devices. Android held 71.93 percent of the market.},
  journal  = {Statista},
  language = {en},
  url      = {https://www.statista.com/statistics/272698/global-market-share-held-by-mobile-operating-systems-since-2009/},
  urldate  = {2021-04-20},
}

@Misc{Statista2020,
  title      = {Google {Play} {Store}: number of apps 2020},
  year       = {2020},
  abstract   = {There were 2.95 million apps available on Google Play as of December 2020. The number of apps offered by the store has fluctuated in recent years.},
  journal    = {Statista},
  language   = {en},
  shorttitle = {Google {Play} {Store}},
  url        = {https://www.statista.com/statistics/266210/number-of-available-applications-in-the-google-play-store/},
  urldate    = {2021-04-20},
}

@InProceedings{Backes2016a,
  author     = {Backes, Michael and Bugiel, Sven and Derr, Erik and Gerling, Sebastian and Hammer, Christian},
  title      = {R-{Droid}: {Leveraging} {Android} {App} {Analysis} with {Static} {Slice} {Optimization}},
  year       = {2016},
  month      = may,
  pages      = {129--140},
  abstract   = {Today's feature-rich smartphone apps intensively rely on access to highly sensitive (personal) data. This puts the user's privacy at risk of being violated by overly curious apps or libraries (like advertisements). Central app markets conceptually represent a first line of defense against such invasions of the user's privacy, but unfortunately we are still lacking full support for automatic analysis of apps' internal data flows and supporting analysts in statically assessing apps' behavior. In this paper we present a novel slice-optimization approach to leverage static analysis of Android applications. Building on top of precise application lifecycle models, we employ a slicing-based analysis to generate data-dependent statements for arbitrary points of interest in an application. As a result of our optimization, the produced slices are, on average, 49\% smaller than standard slices, thus facilitating code understanding and result validation by security analysts. Moreover, by re-targeting strings, our approach enables automatic assessments for a larger number of use-cases than prior work. We consolidate our improvements on statically analyzing Android apps into a tool called R-Droid and conducted a large-scale data-leak analysis on a set of 22,700 Android apps from Google Play. R-Droid managed to identify a significantly larger set of potential privacy-violating information flows than previous work, including 2,157 sensitive flows of password-flagged UI widgets in 256 distinct apps.},
  doi        = {10.1145/2897845.2897927},
  file       = {ResearchGate Link:https\://www.researchgate.net/publication/303601493_R-Droid_Leveraging_Android_App_Analysis_with_Static_Slice_Optimization:},
  shorttitle = {R-{Droid}},
}

@InProceedings{Feichtner2018,
  author    = {Feichtner, Johannes},
  booktitle = {{SEC}},
  title     = {Hunting {Password} {Leaks} in {Android} {Applications}},
  year      = {2018},
  abstract  = {A wide range of mobile applications for the Android operating system require users to input sensitive data, such as PINs or passwords. Given the ubiquitous and security-critical role of credentials, it is paramount that programs process secrets responsibly and do not expose them to unrelated parties. Unfortunately, users have no insight into what happens with their data after entrusting it to an application. In this paper, we introduce a new approach to identify and follow the trace of user input right from the point where it enters an application. By using a combination of static slicing in forward and backward direction, we are able to reveal potential data leaks and can pinpoint their origin. To evaluate the applicability of our solution, we conducted a manual and automated inspection of security-related Android applications that process user-entered secrets. We find that 182 out of 509 (36\%) applications insecurely store given credentials in files or pass them to a log output.},
  doi       = {10.1007/978-3-319-99828-2_20},
  file      = {Semantic Scholar Link:https\://www.semanticscholar.org/paper/Hunting-Password-Leaks-in-Android-Applications-Feichtner/4e58508499a5d46e176dd2246350b6e2dbfc1f64:text/html},
}

@InProceedings{Zhao2020,
  author    = {Zhao, Q. and Zuo, C. and Dolan-Gavitt, B. and Pellegrino, G. and Lin, Z.},
  booktitle = {2020 {IEEE} {Symposium} on {Security} and {Privacy} ({SP})},
  title     = {Automatic {Uncovering} of {Hidden} {Behaviors} {From} {Input} {Validation} in {Mobile} {Apps}},
  year      = {2020},
  month     = may,
  note      = {ISSN: 2375-1207},
  pages     = {1106--1120},
  abstract  = {Mobile applications (apps) have exploded in popularity, with billions of smartphone users using millions of apps available through markets such as the Google Play Store or the Apple App Store. While these apps have rich and useful functionality that is publicly exposed to end users, they also contain hidden behaviors that are not disclosed, such as backdoors and blacklists designed to block unwanted content. In this paper, we show that the input validation behavior-the way the mobile apps process and respond to data entered by users-can serve as a powerful tool for uncovering such hidden functionality. We therefore have developed a tool, InputScope, that automatically detects both the execution context of user input validation and also the content involved in the validation, to automatically expose the secrets of interest. We have tested InputScope with over 150,000 mobile apps, including popular apps from major app stores and preinstalled apps shipped with the phone, and found 12,706 mobile apps with backdoor secrets and 4,028 mobile apps containing blacklist secrets.},
  doi       = {10.1109/SP40000.2020.00072},
  file      = {IEEE Xplore Full Text PDF:https\://ieeexplore.ieee.org/stampPDF/getPDF.jsp?tp=&arnumber=9152205&ref=aHR0cHM6Ly9pZWVleHBsb3JlLmllZWUub3JnL2RvY3VtZW50LzkxNTIyMDU=:application/pdf},
  issn      = {2375-1207},
  keywords  = {Blacklisting, Password, Google, Tools, Syntactics, Semantics},
}

@Article{Li2017,
  author    = {Li Li and Tegawend{\'{e}} F. Bissyand{\'{e}} and Mike Papadakis and Siegfried Rasthofer and Alexandre Bartel and Damien Octeau and Jacques Klein and Le Traon},
  journal   = {Information and Software Technology},
  title     = {Static analysis of android apps: A systematic literature review},
  year      = {2017},
  month     = {aug},
  pages     = {67--95},
  volume    = {88},
  doi       = {10.1016/j.infsof.2017.04.001},
  publisher = {Elsevier {BV}},
}

@TechReport{Fairley1973,
  author      = {Fairley, Richard E.},
  institution = {Department of ComputerScience, University of Colorado},
  title       = {Semantic Models of Parameter Passing},
  year        = {1973},
  url         = {https://core.ac.uk/download/pdf/54846041.pdf},
}

@Comment{jabref-meta: databaseType:bibtex;}
