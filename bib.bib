% Encoding: UTF-8

@Article{Grech2017,
  author     = {Grech, Neville and Smaragdakis, Yannis},
  journal    = {Proceedings of the ACM on Programming Languages},
  title      = {P/{Taint}: unified points-to and taint analysis},
  year       = {2017},
  month      = oct,
  pages      = {1--28},
  volume     = {1},
  abstract   = {Static information-flow analysis (especially taint-analysis) is a key technique in software security, computing where sensitive or untrusted data can propagate in a program. Points-to analysis is a fundamental static program analysis, computing what abstract objects a program expression may point to. In this work, we propose a deep unification of information-flow and points-to analysis. We observe that information-flow analysis is not a mere high-level client of points-to information, but it is indeed identical to points-to analysis on artificial abstract objects that represent different information sources. The very same algorithm can compute, simultaneously, two interlinked but separate results (points-to and information-flow values) with changes only to its initial conditions.
The benefits of such a unification are manifold. We can use existing points-to analysis implementations, with virtually no modification (only minor additions of extra logic for sanitization) to compute information flow concepts, such as value tainting. The algorithmic enhancements of points-to analysis (e.g., different flavors of context sensitivity) can be applied transparently to information-flow analysis. Heavy engineering work on points-to analysis (e.g., handling of the reflection API for Java) applies to information-flow analysis without extra effort. We demonstrate the benefits in a realistic implementation that leverages the Doop points-to analysis framework (including its context-sensitivity and reflection analysis features) to provide an information-flow analysis with excellent precision (over 91\%) and recall (over 99\%) for standard Java information-flow benchmarks.
The analysis comfortably scales to large, real-world Android applications, analyzing the Facebook Messenger app with more than 55K classes in under 7 hours.},
  doi        = {10.1145/3133926},
  file       = {ResearchGate Link:https\://www.researchgate.net/publication/320390381_PTaint_unified_points-to_and_taint_analysis:},
  shorttitle = {P/{Taint}},
}

@Article{Lerch2014,
  author     = {Lerch, J. and Hermann, Ben and Bodden, E. and Mezini, M.},
  journal    = {SIGSOFT FSE},
  title      = {{FlowTwist}: efficient context-sensitive inside-out taint analysis for large codebases},
  year       = {2014},
  abstract   = {Over the past years, widely used platforms such as the Java Class Library have been under constant attack through vulnerabilities that involve a combination of two taint-analysis problems: an integrity problem allowing attackers to trigger sensitive operations within the platform, and a confidentiality problem allowing the attacker to retrieve sensitive information or pointers from the results of those operations. While existing static taint analyses are good at solving either of those problems, we show that they scale prohibitively badly when being applied to situations that require the exploitation of both an integrity and confidentiality problem in combination. The main problem is the huge attack surface of libraries such as the Java Class Library, which exposes thousands of methods potentially controllable by an attacker. In this work we thus present FlowTwist, a novel taint-analysis approach that works inside-out, i.e., tracks data flows from potentially vulnerable calls to the outer level of the API which the attacker might control. This inside-out analysis requires a careful, context-sensitive coordination of both a backward and a forward taint analysis. In this work, we expose a design of the analysis approach based on the IFDS algorithm, and explain several extensions to IFDS that enable not only this coordination but also a helpful reporting of error situations to security analysts. Experiments with the Java Class Library show that, while a simple forward taint-analysis approach does not scale even with much machine power, FlowTwist's algorithm is able to fully analyze the library within 10 minutes.},
  doi        = {10.1145/2635868.2635878},
  file       = {Semantic Scholar Link:https\://www.semanticscholar.org/paper/FlowTwist%3A-efficient-context-sensitive-inside-out-Lerch-Hermann/28f538ccabcc9edbbf27d0f0a027031615936e42:text/html},
  shorttitle = {{FlowTwist}},
}

@Article{Rice1953,
  author   = {Rice, H.},
  title    = {Classes of recursively enumerable sets and their decision problems},
  year     = {1953},
  abstract = {1. Introduction. In this paper we consider classes whose elements are re-cursively enumerable sets of non-negative integers. No discussion of recur-sively enumerable sets can avoid the use of such classes, so that it seems desirable to know some of their properties. We give our attention here to the properties of complete recursive enumerability and complete recursiveness (which may be intuitively interpreted as decidability). Perhaps our most interesting result (and the one which gives this paper its name) is the fact that no nontrivial class is completely recursive. We assume familiarity with a paper of Kleene [5](2), and with ideas which are well summarized in the first sections of a paper of Post Í7].},
  doi      = {10.1090/S0002-9947-1953-0053041-6},
  file     = {Semantic Scholar Link:https\://www.semanticscholar.org/paper/Classes-of-recursively-enumerable-sets-and-their-Rice/664a7d3c60b753a34f1601a7378ca952ea92e9a8:text/html;Full Text PDF:https\://pdfs.semanticscholar.org/664a/7d3c60b753a34f1601a7378ca952ea92e9a8.pdf:application/pdf},
}

@InProceedings{Rodriguez2011,
  author    = {Rodriguez, Jonathan and Lhoták, Ondřej},
  booktitle = {Compiler {Construction}},
  title     = {Actor-{Based} {Parallel} {Dataflow} {Analysis}},
  year      = {2011},
  address   = {Berlin, Heidelberg},
  editor    = {Knoop, Jens},
  pages     = {179--197},
  publisher = {Springer},
  series    = {Lecture {Notes} in {Computer} {Science}},
  abstract  = {Defining algorithms in a way which allows parallel execution is becoming increasingly important as multicore computers become ubiquitous. We present IFDS-A, a parallel algorithm for solving context-sensitive interprocedural finite distributive subset (IFDS) dataflow problems. IFDS-A defines these problems in terms of Actors, and dataflow dependencies as messages passed between these Actors. We implement the algorithm in Scala, and evaluate its performance against a comparable sequential algorithm. With eight cores, IFDS-A is 6.12 times as fast as with one core, and 3.35 times as fast as a baseline sequential algorithm. We also found that Scala’s default Actors implementation is not optimal for this algorithm, and that a custom-built implementation outperforms it by a significant margin. We conclude that Actors are an effective way to parallelize this type of algorithm.},
  doi       = {10.1007/978-3-642-19861-8_11},
  file      = {Springer Full Text PDF:https\://link.springer.com/content/pdf/10.1007%2F978-3-642-19861-8_11.pdf:application/pdf},
  isbn      = {9783642198618},
  keywords  = {Actors , compilers , concurrency , dataflow analysis , IFDS , Scala },
  language  = {en},
}

@InProceedings{Deutsch1994,
  author     = {Deutsch, A.},
  booktitle  = {{PLDI} '94},
  title      = {Interprocedural may-alias analysis for pointers: beyond k-limiting},
  year       = {1994},
  abstract   = {Existing methods for alias analysis of recursive pointer data structures are based on two approximation techniques: k-limiting, and store-based (or equivalently location or region-based) approximations, which blur distinction between elements of recursive data structures. Although notable progress in inter-procedural alias analysis has been recently accomplished, very little progress in the precision of analysis of recursive pointer data structures has been seen since the inception of these approximation techniques by Jones and Muchnick a decade ago. As a result, optimizing, verifying and parallelizing programs with pointers has remained difficult.
We present a new parametric framework for analyzing recursive pointer data structures which can express a new natural class of alias information not accessible to existing methods. The key idea is to represent alias information by pairs of symbolic access paths which are qualified by symbolic descriptions of the positions for which the alias pair holds.
Based on this result, we present an algorithm for interprocedural may-alias analysis with pointers which on numerous examples that occur in practice is much more precise than recently published algorithms [CWZ90, He90, LR92, CBC93].},
  doi        = {10.1145/178243.178263},
  file       = {Semantic Scholar Link:https\://www.semanticscholar.org/paper/Interprocedural-may-alias-analysis-for-pointers%3A-Deutsch/7ff982c9608cfab62c4c5c1a65ad737dae3ab0f8:text/html},
  shorttitle = {Interprocedural may-alias analysis for pointers},
}

@Article{Spaeth2019,
  author   = {Späth, Johannes and Ali, Karim and Bodden, Eric},
  journal  = {Proceedings of the ACM on Programming Languages},
  title    = {Context-, flow-, and field-sensitive data-flow analysis using synchronized {Pushdown} systems},
  year     = {2019},
  month    = jan,
  pages    = {1--29},
  volume   = {3},
  abstract = {Precise static analyses are context-, field- and flow-sensitive. Context- and field-sensitivity are both expressible as context-free language (CFL) reachability problems. Solving both CFL problems along the same data-flow path is undecidable, which is why most flow-sensitive data-flow analyses over-approximate field-sensitivity through k-limited access-path, or through access graphs. Unfortunately, as our experience and this paper show, both representations do not scale very well when used to analyze programs with recursive data structures.
Any single CFL-reachability problem is efficiently solvable, by means of a pushdown system. This work thus introduces the concept of synchronized pushdown systems (SPDS). SPDS encode both procedure calls/returns and field stores/loads as separate but “synchronized” CFL reachability problems. An SPDS solves both individual problems precisely, and approximation occurs only in corner cases that are apparently rare in practice: at statements where both problems are satisfied but not along the same data-flow path.
SPDS are also efficient: formal complexity analysis shows that SPDS shift the complexity from {\textbar}F{\textbar}3k under k-limiting to {\textbar}S{\textbar}{\textbar}F{\textbar}², where F is the set of fields and S the set of statements involved in a data-flow. Our evaluation using DaCapo shows this shift to pay off in practice: SPDS are almost as efficient as k-limiting with k=1 although their precision equals k=∞. For a typestate analysis SPDS accelerate the analysis up to 83× for data-flows of objects that involve many field accesses but span rather few methods.
We conclude that SPDS can provide high precision and further improve scalability, in particularly when used in analyses that expose rather local data flows.},
  doi      = {10.1145/3290361},
  file     = {ResearchGate Link:https\://www.researchgate.net/publication/330152854_Context-_flow-_and_field-sensitive_data-flow_analysis_using_synchronized_Pushdown_systems:},
}

@InProceedings{Lam2011,
  author     = {Lam, Patrick and Bodden, Eric and Lhotak, Ondrej and Hendren, Laurie},
  title      = {The {Soot} framework for {Java} program analysis: a retrospective},
  year       = {2011},
  month      = oct,
  language   = {en},
  shorttitle = {The {Soot} framework for {Java} program analysis},
  url        = {http://www.bodden.de/pubs/lblh11soot.pdf},
  urldate    = {2021-03-11},
}

@InProceedings{Rasthofer2014,
  author    = {Rasthofer, Siegfried and Arzt, Steven and Bodden, E.},
  booktitle = {{NDSS}},
  title     = {A {Machine}-learning {Approach} for {Classifying} and {Categorizing} {Android} {Sources} and {Sinks}},
  year      = {2014},
  abstract  = {Today’s smartphone users face a security dilemma: many apps they install operate on privacy-sensitive data, although 
they might originate from developers whose trustworthiness is hard to judge. Researchers have addressed the problem with more and more sophisticated static and dynamic analysis tools as an aid to assess how apps use private user data. Those tools, however, rely on the manual configuration of lists of sources of sensitive data as well as sinks which might leak data to untrusted observers. Such lists are hard to come by. 
 
We thus propose SUSI, a novel machine-learning guided approach for identifying sources and sinks directly from the code of any Android API. Given a training set of hand-annotated sources and sinks, SUSI identifies other sources and sinks in the entire API. To provide more fine-grained information, SUSI further categorizes the sources (e.g., unique identifier, location information, etc.) and sinks (e.g., network, file, etc.). 
 
For Android 4.2, SUSI identifies hundreds of sources and sinks with over 92\% accuracy, many of which are missed by current information-flow tracking tools. An evaluation of about 11,000 malware samples confirms that many of these sources and sinks are indeed used. We furthermore show that SUSI can reliably classify sources and sinks even in new, previously unseen Android versions and components like Google Glass or the Chromecast API.},
  doi       = {10.14722/NDSS.2014.23039},
  file      = {Semantic Scholar Link:https\://www.semanticscholar.org/paper/A-Machine-learning-Approach-for-Classifying-and-and-Rasthofer-Arzt/33987e58b45755a6120905ce582fc9cbec434763:text/html;Full Text PDF:https\://pdfs.semanticscholar.org/5a8e/d3604393818fe1bca9396e55ea6bd320e49c.pdf:application/pdf},
}

@Book{Aho1986,
  author       = {Aho, Alfred V. and Sethi, Ravi and Ullman, Jeffrey D.},
  publisher    = {Reading, Mass. : Addison-Wesley Pub. Co.},
  title        = {Compilers, principles, techniques, and tools},
  year         = {1986},
  isbn         = {9780201100884},
  abstract     = {Bibliography: p. [752]-779; Includes index},
  collaborator = {{Internet Archive}},
  keywords     = {Compilers (Computer programs)},
  language     = {eng},
  url          = {http://archive.org/details/compilersprincip00ahoa},
  urldate      = {2021-02-15},
}

@Book{Thain2019,
  author    = {Thain, Douglas},
  publisher = {Lulu.com},
  title     = {Introduction to {Compilers} and {Language} {Design}},
  year      = {2019},
  isbn      = {9780359138043},
  month     = jul,
  note      = {Google-Books-ID: 5mVyDwAAQBAJ},
  abstract  = {A compiler translates a program written in a high level language into a program written in a lower level language. For students of computer science, building a compiler from scratch is a rite of passage: a challenging and fun project that offers insight into many different aspects of computer science, some deeply theoretical, and others highly practical. This book offers a one semester introduction into compiler construction, enabling the reader to build a simple compiler that accepts a C-like language and translates it into working X86 or ARM assembly language. It is most suitable for undergraduate students who have some experience programming in C, and have taken courses in data structures and computer architecture.},
  file      = {Google Books Link:https\://books.google.de/books?id=5mVyDwAAQBAJ:text/html},
  keywords  = {Computers / General},
  language  = {en},
}

@PhdThesis{Arzt2017PhD,
  author    = {Arzt, Steven},
  school    = {Technische Universität},
  title     = {Static {Data} {Flow} {Analysis} for {Android} {Applications}},
  year      = {2017},
  address   = {Darmstadt},
  abstract  = {Mobile phones have become important daily companions for millions of people which help to organize both their private and their professional lives. Having access to data such as the calendar or the address book anywhere, anytime, has become commonplace. Sensor data such as the phone's GPS location and accelerometer help users navigate through the physical world. Users can furthermore extend the functionality of their phone using small programs called apps from various developers and vendors in an open ecosystem. Undoubtedly, having all this data merged on a device that is always-on and always-connected and that can easily be extended with new software greatly improves user convenience. On the other hand, it also poses new questions with regard to privacy and security. Apps may misuse the data stored on the phone or obtained from the sensors to infringe upon the user's privacy. In fact, companies already now use location data and app usage statistics to build user profiles for the purpose of targeted advertisement. The user is oftentimes unaware of these data leaks originating from his phone and has little means for analyzing the actual behavior of a given app with regard to privacy.

Static data flow analysis has been proposed as a means for automatically enumerating the data flows inside a program. Still, either do not support Android's platform-specific semantics or fall short on precision, recall, or scalability. In this thesis, we therefore propose techniques for efficiently and precisely performing static data flow analysis on real-world binary-only Android apps with large code sizes. We present the FlowDroid tool and show that it can detect data leaks in popular apps such as Facebook, Paypal, and LinkedIn. The FlowDroid reports improve the user's digital sovereignty by allowing his to asses the behavior of the app before installing it on his device and thereby entrusting it with his personal data. We allow the user to verify which of his data leaves the device and how. On the DroidBench micro-benchmark suite, we show that FlowDroid achieves a precision of more than 87\% and a recall of over 84\%, thereby outperforming state-of-the-art tools from academia and industry. Additionally, FlowDroid has already been used as a building-block for many other works in the field.},
  copyright = {lediglich die vom Gesetz vorgesehenen Nutzungsrechte gemäß UrhG},
  file      = {Full Text PDF:https\://tuprints.ulb.tu-darmstadt.de/5937/7/Thesis.pdf:application/pdf},
  language  = {en},
  url       = {https://tuprints.ulb.tu-darmstadt.de/5937/},
  urldate   = {2021-01-28},
}

@InProceedings{Lerch2015,
  author    = {Johannes Lerch and Ben Hermann},
  booktitle = {Proceedings of the 4th {ACM} {SIGPLAN} International Workshop on State Of the Art in Program Analysis},
  title     = {Design your analysis: a case study on implementation reusability of data-flow functions},
  year      = {2015},
  month     = {jun},
  publisher = {{ACM}},
  doi       = {10.1145/2771284.2771289},
}

@InProceedings{Reps1995,
  author    = {Thomas Reps and Susan Horwitz and Mooly Sagiv},
  booktitle = {Proceedings of the 22nd {ACM} {SIGPLAN}-{SIGACT} symposium on Principles of programming languages - {POPL} {\textquotesingle}95},
  title     = {Precise interprocedural dataflow analysis via graph reachability},
  year      = {1995},
  publisher = {{ACM} Press},
  doi       = {10.1145/199448.199462},
}

@InCollection{Naeem2010,
  author    = {Nomair A. Naeem and Ond{\v{r}}ej Lhot{\'{a}}k and Jonathan Rodriguez},
  booktitle = {Lecture Notes in Computer Science},
  publisher = {Springer Berlin Heidelberg},
  title     = {Practical Extensions to the {IFDS} Algorithm},
  year      = {2010},
  pages     = {124--144},
  doi       = {10.1007/978-3-642-11970-5_8},
}

@Article{Arzt2014,
  author    = {Steven Arzt and Siegfried Rasthofer and Christian Fritz and Eric Bodden and Alexandre Bartel and Jacques Klein and Yves Le Traon and Damien Octeau and Patrick McDaniel},
  journal   = {{ACM} {SIGPLAN} Notices},
  title     = {{FlowDroid}},
  year      = {2014},
  month     = {jun},
  number    = {6},
  pages     = {259--269},
  volume    = {49},
  doi       = {10.1145/2666356.2594299},
  publisher = {Association for Computing Machinery ({ACM})},
}

@Article{Valleerai2004,
  author     = {Vallee-rai, Raja and Hendren, Laurie},
  title      = {Jimple: {Simplifying} {Java} {Bytecode} for {Analyses} and {Transformations}},
  year       = {2004},
  month      = jan,
  abstract   = {In this paper we present Jimple, a 3-address intermediaterepresentation that has been designed tosimplify analysis and transformation of Java bytecode.We motivate the need for a new intermediaterepresentation by illustrating several difficultieswith optimizing the stack-based Java bytecode directly.In general, these difficulties are due to thefact that bytecode instructions affect an expressionstack, and thus have implicit uses and definitions ofstack locations. We propose Jimple as an ...},
  file       = {ResearchGate Link:https\://www.researchgate.net/publication/243776080_Jimple_Simplifying_Java_Bytecode_for_Analyses_and_Transformations:},
  shorttitle = {Jimple},
}

@InProceedings{Bodden2012,
  author    = {Eric Bodden},
  booktitle = {Proceedings of the {ACM} {SIGPLAN} International Workshop on State of the Art in Java Program analysis - {SOAP} {\textquotesingle}12},
  title     = {Inter-procedural data-flow analysis with {IFDS}/{IDE} and Soot},
  year      = {2012},
  publisher = {{ACM} Press},
  doi       = {10.1145/2259051.2259052},
}

@InProceedings{Yan2017,
  author    = {Yan, X. and Ma, H. and Wang, Q.},
  booktitle = {2017 {IEEE} 9th {International} {Conference} on {Communication} {Software} and {Networks} ({ICCSN})},
  title     = {A static backward taint data analysis method for detecting web application vulnerabilities},
  year      = {2017},
  month     = may,
  note      = {ISSN: 2472-8489},
  pages     = {1138--1141},
  abstract  = {This paper addresses detecting taint-style vulnerabilities in PHP code. It extends classical taint-style model with an element called “cleans”, which is used to specify sanitation routines. Based on the new model, a static backward taint data analysis method is proposed to detecting taint-style vulnerabilities. This method includes four key steps, first of which is collecting sinks and constructing contexts, the second is backward tracing variables during a basic block, the third is tracing variables between blocks, and the last is tracing variables crossing function call. A tool called POSE implements this method and testing results show that the method is valid for detecting taint-style web application vulnerabilities.},
  doi       = {10.1109/ICCSN.2017.8230288},
  file      = {IEEE Xplore Full Text PDF:https\://ieeexplore.ieee.org/stampPDF/getPDF.jsp?tp=&arnumber=8230288&ref=aHR0cHM6Ly9pZWVleHBsb3JlLmllZWUub3JnL2RvY3VtZW50LzgyMzAyODg=:application/pdf},
  issn      = {2472-8489},
  keywords  = {data analysis, Internet, program diagnostics, programming, security of data, software tools, static backward taint data analysis method, taint-style web application vulnerabilities, classical taint-style model, POSE implements, PHP code, Web application vulnerabilities detection, taint-style vulnerabilities detection, Data analysis, Data models, Tools, Algorithm design and analysis, Reactive power, taint data analysis, PHP, web application, vulnerabilities},
}

@Book{Muchnick1997,
  author    = {Steven S. Muchnick},
  publisher = {Morgan Kaufmann},
  title     = {Advanced Compiler Design and Implementation},
  year      = {1997},
  isbn      = {1-55860-320-4},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/books/mk/Muchnick1997.bib},
  timestamp = {Mon, 05 Jan 2004 14:58:03 +0100},
}

@Book{Khedker2009,
  author     = {Khedker, Uday and Sanyal, Amitabha and Sathe, Bhaurao},
  title      = {Data {Flow} {Analysis}: {Theory} and {Practice}},
  year       = {2009},
  isbn       = {9780849332517},
  month      = jan,
  abstract   = {This work provides an in-depth treatment of data flow analysis technique. Apart from including interprocedural data flow analysis, this book is the first to extend detailed coverage of analysis beyond bit vectors. Supplemented by numerous examples, it equips readers with a combination of mutually supportive theory and practice, presenting mathematical foundations and including study of data flow analysis implementation through use of the GNU Compiler Collection (GCC). Readers can experiment with the analyses described in the book by accessing the authors web page, where they will find the source code of gdfa (generic data flow analyzer).},
  doi        = {10.1201/9780849332517},
  file       = {ResearchGate Link:https\://www.researchgate.net/publication/262493821_Data_Flow_Analysis_Theory_and_Practice:},
  journal    = {Data Flow Analysis: Theory and Practice},
  shorttitle = {Data {Flow} {Analysis}},
}

@InProceedings{Jones1979,
  author   = {Jones, Neil and Muchnick, Steven},
  title    = {Flow {Analysis} and {Optimization} of {Lisp}-{Like} {Structures}.},
  year     = {1979},
  month    = jan,
  pages    = {244--256},
  abstract = {In [12] the authors introduced the concept of binding time optimization and presented a series of data flow analytic methods for determining some of the binding time characteristics of programs. In this paper we extend that work by providing methods for determining the class of shapes which an unbounded data object may assume during execution of a LISP-like program, and describe a number of uses to which that information may be put to improve storage allocation in compilers and interpreters for advanced programming languages.We are concerned chiefly with finding, for each program point and variable a finite description of a set of graphs which includes all the shapes of values the variable could assume at that point during the execution of a program. If this set is small or regular in structure, this information can be used to optimize the program's execution, mainly by use of more efficient storage allocation schemes.In the first part we show how to construct from a program without selective updating a tree grammar whose nonterminals generate the desired sets of graphs; in this case they will all be trees. The tree grammars are of a more general form than is usually studied [8, 19], so we show that they may be converted to the usual form. The resulting tree grammar could naturally be viewed as a recursive type definition [11] of the values the variables may assume. Further, standard algorithms may be employed to test for infiniteness, emptiness or linearity of the tree structure.In the second part selective updating is allowed, so an alternate semantics is introduced which more closely resembles traditional LISP implementations, and which is equivalent to the tree model for programs without selective updating. In this model data objects are directed graphs. We devise a finite approximation method which provides enough information to detect cell sharing and cyclic structures whenever they can possibly occur. This information can be used to recognize when the use of garbage collection or of reference counts may be avoided.The work reported in the second part of this paper extends that of Schwartz [17] and Cousot and Cousot [7]. They have developed methods for determining whether the values of two or more variables share cells, while we provide information on the detailed structure of what is shared. The ability to detect cycles is also new. It also extends the work of Kaplan [13], who distinguishes only binary relations among the variables of a program, does not handle cycles, and does not distinguish selectors (so that his analysis applies to nodes representing sets rather than ordered tuples).},
  doi      = {10.1145/567752.567776},
  file     = {Full Text PDF:https\://www.researchgate.net/profile/Neil-Jones-12/publication/220997426_Flow_Analysis_and_Optimization_of_Lisp-Like_Structures/links/00b4951922ad3ee2bc000000/Flow-Analysis-and-Optimization-of-Lisp-Like-Structures.pdf:application/pdf;ResearchGate Link:https\://www.researchgate.net/publication/220997426_Flow_Analysis_and_Optimization_of_Lisp-Like_Structures:},
}

@InProceedings{Bravenboer2009,
  author   = {Bravenboer, M. and Smaragdakis, Yannis},
  title    = {Strictly {Declarative} {Specification} of {Sophisticated} {Points}-to {Analyses}},
  year     = {2009},
  month    = oct,
  pages    = {243--262},
  volume   = {44},
  abstract = {We present the DOOP framework for points-to analysis of Java programs. DOOP builds on the idea of specifying pointer analysis algorithms declaratively, using Datalog: a logic-based language for defining (recursive) relations. We carry the declarative approach further than past work by describing the full end-to-end analysis in Datalog and optimizing aggressively using a novel technique specifically targeting highly recursive Datalog programs.
As a result, DOOP achieves several benefits, including full order-of-magnitude improvements in runtime. We compare DOOP with Lhotak and Hendren's PADDLE, which defines the state of the art for context-sensitive analyses. For the exact same logical points-to definitions (and, consequently, identical precision) DOOP is more than 15x faster than PADDLE for a 1-call-site sensitive analysis of the DaCapo benchmarks, with lower but still substantial speedups for other important analyses. Additionally, DOOP scales to very precise analyses that are impossible with PADDLE and Whaley et al.'s bddbddb, directly addressing open problems in past literature. Finally, our implementation is modular and can be easily configured to analyses with a wide range of characteristics, largely due to its declarativeness.},
  doi      = {10.1145/1640089.1640108},
  file     = {Full Text PDF:https\://www.researchgate.net/profile/M-Bravenboer/publication/221321022_Strictly_Declarative_Specification_of_Sophisticated_Points-to_Analyses/links/552413cd0cf2caf11bfcbf1e/Strictly-Declarative-Specification-of-Sophisticated-Points-to-Analyses.pdf:application/pdf;ResearchGate Link:https\://www.researchgate.net/publication/221321022_Strictly_Declarative_Specification_of_Sophisticated_Points-to_Analyses:},
}

@Comment{jabref-meta: databaseType:bibtex;}
